{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"dataset/rag_truth_test.json\", \"r\") as f:\n",
    "    test_data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ref': 'The FBI charged a Philadelphia woman on Thursday with trying to travel overseas to fight for ISIS. She\\'s one of three women arrested this week on terror charges. Two New York women were also taken into custody. An FBI complaint cites numerous social media messages dating back to August 2013 that were sent by Keonna Thomas, 30, also known as \"Young Lioness\" and \"Fatayat Al Khilafah.\" One Twitter message said, \"If we truly knew the realities ... we all would be rushing to join our brothers in the front lines pray ALLAH accept us as shuhada [martyrs].\" Another said, \"When you\\'re a mujahid [violent jihadi fighter] your death becomes a wedding.\" The FBI said Thomas purchased an electronic visa to Turkey on March 23. Turkey is known as the easiest place from which to enter Syria and join ISIS. An ISIS manual advises recruits to buy round-trip tickets to vacation spots such as Spain and then purchase tickets for their real destination once they arrive overseas, the FBI said. On March 26, Thomas purchased a ticket to Barcelona, with a March 29 departure and an April 15 return to the United States, the complaint said. It\\'s not clear when or where she was arrested. She was charged with knowingly attempting to provide material support and resources to a designated foreign terrorist organization. She could be sentenced to 15 years in prison. On Thursday, Noelle Velentzas, 28, and her former roommate, Asia Siddiqui, 31, were arrested in New York and accused of planning to build an explosive device for attacks in the United States, federal prosecutors said. In the past 18 months, the Justice Department\\'s National Security Division has prosecuted or is prosecuting more than 30 cases of people attempting to travel abroad to join or provide support to terrorist groups. Of those cases, 18 allegedly involve support to ISIS. \"The terrorist threat is more decentralized, more diffuse, more complicated,\" Homeland Security Secretary Jeh Johnson told reporters Thursday. \"It involves the potential lone wolf actor, it involves the effective use of social media, the Internet.\"\\n',\n",
       " 'text': 'Please judge the following statement as true or false (based on the references above): The FBI has charged a Philadelphia woman, Keonna Thomas, with trying to travel overseas to fight for ISIS. This follows the arrests of two New York women, Noelle Velentzas and Asia Siddiqui, who were accused of planning to build an explosive device for attacks in the United States. Thomas purchased an electronic visa to Turkey and a round-trip ticket to Barcelona, following the advice given in an ISIS manual for recruits. She has been charged with attempting to provide material support to a terrorist organisation and could face 15 years in prison.',\n",
       " 'labels': 0,\n",
       " 'source': 'CNN/DM',\n",
       " 'model': 'gpt-4-0613',\n",
       " 'task_type': 'Summary',\n",
       " 'source_id': '15596'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_prefix(data):\n",
    "    for d in data:\n",
    "        d[\"text\"] = \"Please judge the following statement whether it includes hallucination or not (based on the references above): \" + d[\"text\"]\n",
    "    return data\n",
    "\n",
    "\n",
    "test_data = add_prefix(test_data)\n",
    "test_data[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_type: QA, Data2txt, Summary\n",
    "task_name = \"Summary\"\n",
    "test_data = [d for d in test_data if d[\"task_type\"] == task_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    dev: Dataset({\n",
       "        features: ['ref', 'text', 'labels', 'source', 'model', 'task_type', 'source_id'],\n",
       "        num_rows: 900\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "test_df = pd.DataFrame(test_data)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "\n",
    "raw_datasets = DatasetDict({\"test\":test_ds})\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-23 13:24:49.871431: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-23 13:24:50.268171: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-23 13:24:50.448942: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-23 13:24:50.449335: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-23 13:24:50.779741: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-23 13:24:52.953728: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d16f1e2bf65455a920f9b9831e92d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from models_phi import NoDocModel\n",
    "\n",
    "base_model = AutoModel.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\")\n",
    "# load trained model\n",
    "name = \"./trained/no_doc_phi\"\n",
    "model = NoDocModel.from_pretrained(base_model,name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4d114714b7403c8251141fa07d9d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=512)\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    dev: Dataset({\n",
       "        features: ['ref', 'labels', 'source', 'model', 'task_type', 'source_id', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 900\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0, 'label': 0, 'task': 'Summary'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for i, d in enumerate(tokenized_datasets[\"test\"]):\n",
    "    results.append({\"id\": i,\"label\":d[\"labels\"],\"task\":d[\"task_type\"]})\n",
    "\n",
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_bmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/gs/fs/tga-arase-student/yamada/check_improve.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ood.t4.gsic.titech.ac.jp/gs/fs/tga-arase-student/yamada/check_improve.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m attention_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(d[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ood.t4.gsic.titech.ac.jp/gs/fs/tga-arase-student/yamada/check_improve.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='vscode-notebook-cell://ood.t4.gsic.titech.ac.jp/gs/fs/tga-arase-student/yamada/check_improve.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(input_ids\u001b[39m=\u001b[39;49minput_ids, attention_mask\u001b[39m=\u001b[39;49mattention_mask)\n\u001b[1;32m     <a href='vscode-notebook-cell://ood.t4.gsic.titech.ac.jp/gs/fs/tga-arase-student/yamada/check_improve.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     logits \u001b[39m=\u001b[39m outputs[\u001b[39m\"\u001b[39m\u001b[39mlogits\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ood.t4.gsic.titech.ac.jp/gs/fs/tga-arase-student/yamada/check_improve.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     predicted_index \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(logits, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/gs/fs/tga-arase-student/yamada/nlp/lib64/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/gs/fs/tga-arase-student/yamada/nlp/lib64/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/gs/fs/tga-arase-student/yamada/models.py:21\u001b[0m, in \u001b[0;36mNoRagModel.forward\u001b[0;34m(self, input_ids, attention_mask, labels)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_ids, attention_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 21\u001b[0m     text_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_model(input_ids\u001b[39m=\u001b[39;49minput_ids, attention_mask\u001b[39m=\u001b[39;49mattention_mask)[\u001b[39m0\u001b[39m][:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,:]\n\u001b[1;32m     22\u001b[0m     \u001b[39m#text_output = text_output.mean(dim=1)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[39m#print(text_output.shape)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     text_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(text_output)\n",
      "File \u001b[0;32m/gs/fs/tga-arase-student/yamada/nlp/lib64/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/gs/fs/tga-arase-student/yamada/nlp/lib64/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/gs/fs/tga-arase-student/yamada/nlp/lib64/python3.9/site-packages/transformers/models/phi3/modeling_phi3.py:605\u001b[0m, in \u001b[0;36mPhi3Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m hidden_states \u001b[39m=\u001b[39m inputs_embeds\n\u001b[1;32m    604\u001b[0m \u001b[39m# create position embeddings to be shared across the decoder layers\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m position_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrotary_emb(hidden_states, position_ids)\n\u001b[1;32m    607\u001b[0m \u001b[39m# decoder layers\u001b[39;00m\n\u001b[1;32m    608\u001b[0m all_hidden_states \u001b[39m=\u001b[39m () \u001b[39mif\u001b[39;00m output_hidden_states \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/gs/fs/tga-arase-student/yamada/nlp/lib64/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/gs/fs/tga-arase-student/yamada/nlp/lib64/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/gs/fs/tga-arase-student/yamada/nlp/lib64/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/gs/fs/tga-arase-student/yamada/nlp/lib64/python3.9/site-packages/transformers/models/phi3/modeling_phi3.py:368\u001b[0m, in \u001b[0;36mPhi3RotaryEmbedding.forward\u001b[0;34m(self, x, position_ids)\u001b[0m\n\u001b[1;32m    366\u001b[0m device_type \u001b[39m=\u001b[39m device_type \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(device_type, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m device_type \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    367\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautocast(device_type\u001b[39m=\u001b[39mdevice_type, enabled\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 368\u001b[0m     freqs \u001b[39m=\u001b[39m (inv_freq_expanded\u001b[39m.\u001b[39;49mfloat() \u001b[39m@\u001b[39;49m position_ids_expanded\u001b[39m.\u001b[39;49mfloat())\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m    369\u001b[0m     emb \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((freqs, freqs), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    370\u001b[0m     cos \u001b[39m=\u001b[39m emb\u001b[39m.\u001b[39mcos()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_bmm)"
     ]
    }
   ],
   "source": [
    "# inference\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for i,d in tqdm(enumerate(tokenized_datasets[\"test\"])):\n",
    "    input_ids =torch.tensor(d[\"input_ids\"]).unsqueeze(0).to(device)\n",
    "    attention_mask = torch.tensor(d[\"attention_mask\"]).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs[\"logits\"]\n",
    "        predicted_index = torch.argmax(logits, dim=-1) # predicted label\n",
    "    results[i][\"no_rag_logits\"] = logits.cpu().numpy()\n",
    "    results[i][\"no_rag_label\"] = predicted_index.cpu().numpy()\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### with_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb6327ca5464d08a86c934582384281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70afe8d1e124e1da287ba460fcf1af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, DataCollatorWithPadding\n",
    "import torch\n",
    "from models_phi import WithDocModel\n",
    "\n",
    "base_model = AutoModel.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\")\n",
    "\n",
    "name = \"./trained/with_doc_phi\"\n",
    "model = WithDocModel.from_pretrained(base_model,name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    ref = tokenizer(examples[\"ref\"],truncation=True, max_length=512)\n",
    "    text = tokenizer(examples[\"text\"],truncation=True, max_length=512)\n",
    "    return {\n",
    "        \"ref_input_ids\":ref[\"input_ids\"],\n",
    "        \"ref_attention_mask\":ref[\"attention_mask\"],\n",
    "        \"text_input_ids\":text[\"input_ids\"],\n",
    "        \"text_attention_mask\":text[\"attention_mask\"],\n",
    "    }\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\",\"ref\"])\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2700it [12:19,  3.65it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for i,d in tqdm(enumerate(tokenized_datasets[\"dev\"])):\n",
    "    ref_input_ids = torch.tensor(d[\"ref_input_ids\"]).unsqueeze(0).to(device)\n",
    "    text_input_ids = torch.tensor(d[\"text_input_ids\"]).unsqueeze(0).to(device)\n",
    "    input_ids = [ref_input_ids, text_input_ids]\n",
    "    \n",
    "    ref_attention_mask = torch.tensor(d[\"ref_attention_mask\"]).unsqueeze(0).to(device)\n",
    "    text_attention_mask = torch.tensor(d[\"text_attention_mask\"]).unsqueeze(0).to(device)\n",
    "    attention_mask = [ref_attention_mask, text_attention_mask]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs[\"logits\"]\n",
    "        predicted_index = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "    results[i][\"rag_logits\"] = logits.cpu().numpy()\n",
    "    results[i][\"rag_label\"] = predicted_index.cpu().numpy()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triplet loss is not calculated during inference, so the other data is dummy (\"hallucination\"/\"not hallucination\")\n",
    "\n",
    "def create_trip_ver2(data):\n",
    "    trip = []\n",
    "    for d in data:\n",
    "        if d[\"labels\"] == 0: # not hallucination\n",
    "            trip.append({\"anchor\":d[\"ref\"],\"positive\": d[\"text\"], \"negative\": \"hallucination\", \"labels\": 0})\n",
    "        else:\n",
    "            trip.append({\"anchor\":d[\"ref\"],\"positive\": \"not hallucination\", \"negative\": d[\"text\"], \"labels\": 1})\n",
    "    return trip\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    dev: Dataset({\n",
       "        features: ['anchor', 'positive', 'negative', 'labels'],\n",
       "        num_rows: 2700\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "\n",
    "test_trip = create_trip_ver2(test_data)\n",
    "\n",
    "test_df = pd.DataFrame(test_trip)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "\n",
    "raw_datasets = DatasetDict({\"test\":test_ds})\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def triplet_loss(anchor_output, positive_output, negative_output, positive_logits, negative_logits):\n",
    "    positive_targets = torch.zeros(positive_output.size(0), dtype=torch.long).to(device)  # not hallucination\n",
    "    negative_targets = torch.ones(negative_output.size(0), dtype=torch.long).to(device)\n",
    "    positive_loss = nn.CrossEntropyLoss()(positive_logits, positive_targets)\n",
    "    negative_loss = nn.CrossEntropyLoss()(negative_logits, negative_targets)\n",
    "\n",
    "    classification_loss = (positive_loss + negative_loss) / 2.0\n",
    "\n",
    "    triplet_loss_fn = (nn.TripletMarginWithDistanceLoss(margin=1.0,distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y)))\n",
    "    triplet_loss = triplet_loss_fn(anchor_output, positive_output, negative_output)\n",
    "\n",
    "    return classification_loss, triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc882d1ca0c1429fab6194f96fb24484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8a64db48c540f8b9f62a6f86a129bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, DataCollatorWithPadding\n",
    "import torch\n",
    "from models_phi import TripletModel\n",
    "\n",
    "\n",
    "base_model = AutoModel.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\")\n",
    "\n",
    "name = \"./trained/triplet_phi\"\n",
    "model = TripletModel.from_pretrained(base_model, triplet_loss, name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    anchor = tokenizer(examples[\"anchor\"], truncation=True,max_length=512)\n",
    "    positive = tokenizer(examples[\"positive\"], truncation=True,max_length=512)\n",
    "    negative = tokenizer(examples[\"negative\"], truncation=True,max_length=512)\n",
    "\n",
    "    return {\n",
    "        \"anchor_input_ids\": anchor[\"input_ids\"],\n",
    "        \"anchor_attention_mask\": anchor[\"attention_mask\"],\n",
    "        \"positive_input_ids\": positive[\"input_ids\"],\n",
    "        \"positive_attention_mask\": positive[\"attention_mask\"],\n",
    "        \"negative_input_ids\": negative[\"input_ids\"],\n",
    "        \"negative_attention_mask\": negative[\"attention_mask\"],\n",
    "    }\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"anchor\", \"positive\", \"negative\"])\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2700it [15:29,  2.90it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for i,d in tqdm(enumerate(tokenized_datasets[\"test\"])):\n",
    "    \n",
    "    flag = False # hallusination → True\n",
    "    if d[\"labels\"] == 1:\n",
    "        flag = True\n",
    "    \n",
    "    anchor_input_ids = torch.tensor(d[\"anchor_input_ids\"], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    positive_input_ids = torch.tensor(d[\"positive_input_ids\"], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    negative_input_ids = torch.tensor(d[\"negative_input_ids\"], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    input_ids = [anchor_input_ids, positive_input_ids, negative_input_ids]\n",
    "    anchor_attention_mask = torch.tensor(d[\"anchor_attention_mask\"], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    positive_attention_mask = torch.tensor(d[\"positive_attention_mask\"], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    negative_attention_mask = torch.tensor(d[\"negative_attention_mask\"], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    attention_mask = [anchor_attention_mask, positive_attention_mask, negative_attention_mask]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        if flag:\n",
    "            logits = outputs.logits[1] # negative_logit\n",
    "        else:\n",
    "            logits = outputs.logits[0] # positive_logit\n",
    "        predicted_index = torch.argmax(logits, dim=-1)\n",
    "    results[i][\"triplet_logits\"] = logits.cpu().numpy()\n",
    "    results[i][\"triplet_label\"] = predicted_index.cpu().numpy()\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 2699,\n",
       " 'label': 0,\n",
       " 'task': 'QA',\n",
       " 'no_rag_logits': [[5.56593656539917, -5.5176544189453125]],\n",
       " 'no_rag_label': [0],\n",
       " 'rag_logits': [[2.7037570476531982, -1.0352840423583984]],\n",
       " 'rag_label': [0],\n",
       " 'triplet_logits': [[1.4126927852630615, -0.585303544998169]],\n",
       " 'triplet_label': [0]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "for result in results:\n",
    "    if isinstance(result[\"no_rag_logits\"], np.ndarray):\n",
    "        result[\"no_rag_logits\"] = result[\"no_rag_logits\"].tolist()\n",
    "    if isinstance(result[\"rag_logits\"], np.ndarray):\n",
    "        result[\"rag_logits\"] = result[\"rag_logits\"].tolist()\n",
    "    if isinstance(result[\"triplet_logits\"], np.ndarray):\n",
    "        result[\"triplet_logits\"] = result[\"triplet_logits\"].tolist()\n",
    "    if isinstance(result[\"no_rag_label\"], np.ndarray):\n",
    "        result[\"no_rag_label\"] = result[\"no_rag_label\"].tolist()\n",
    "    if isinstance(result[\"rag_label\"], np.ndarray):\n",
    "        result[\"rag_label\"] = result[\"rag_label\"].tolist()\n",
    "    if isinstance(result[\"triplet_label\"], np.ndarray):\n",
    "        result[\"triplet_label\"] = result[\"triplet_label\"].tolist()\n",
    "\n",
    "\n",
    "with open(\"check_improve_phi.json\", \"w\") as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('check_improve_phi.json',\"r\") as f:\n",
    "    results = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "972 181 502 169 71 80 212 513\n"
     ]
    }
   ],
   "source": [
    "# compare no_doc and triplet\n",
    "\n",
    "id_000 = [] # both success not to detect\n",
    "id_001 = [] # both fail to detect\n",
    "id_010 = [] # over-detect in triplet\n",
    "id_011 = [] # success to detect only in triplet\n",
    "id_100 = [] # success not to detect only i triplet\n",
    "id_101 = [] # fail to detect only in triplet\n",
    "id_110 = [] # both over-detect\n",
    "id_111 = [] # both success to detect\n",
    "\n",
    "for result in results:\n",
    "    if result[\"no_rag_label\"][0]==0 and result[\"triplet_label\"][0]==0 and result[\"label\"]==0:\n",
    "        id_000.append(result[\"id\"])\n",
    "    elif result[\"no_rag_label\"][0]==0 and result[\"triplet_label\"][0]==0 and result[\"label\"]==1:\n",
    "        id_001.append(result[\"id\"])\n",
    "    elif result[\"no_rag_label\"][0]==0 and result[\"triplet_label\"][0]==1 and result[\"label\"]==0:\n",
    "        id_010.append(result[\"id\"])\n",
    "    elif result[\"no_rag_label\"][0]==0 and result[\"triplet_label\"][0]==1 and result[\"label\"]==1:\n",
    "        id_011.append(result[\"id\"])\n",
    "    elif result[\"no_rag_label\"][0]==1 and result[\"triplet_label\"][0]==0 and result[\"label\"]==0:\n",
    "        id_100.append(result[\"id\"])\n",
    "    elif result[\"no_rag_label\"][0]==1 and result[\"triplet_label\"][0]==0 and result[\"label\"]==1:\n",
    "        id_101.append(result[\"id\"])\n",
    "    elif result[\"no_rag_label\"][0]==1 and result[\"triplet_label\"][0]==1 and result[\"label\"]==0:\n",
    "        id_110.append(result[\"id\"])\n",
    "    elif result[\"no_rag_label\"][0]==1 and result[\"triplet_label\"][0]==1 and result[\"label\"]==1:\n",
    "        id_111.append(result[\"id\"])\n",
    "    \n",
    "    \n",
    "# 000:972, 001:181, 010:502, 011:169, 100:71, 101:80, 110:212, 111:513\n",
    "print(len(id_000),len(id_001),len(id_010),len(id_011),len(id_100),len(id_101),len(id_110),len(id_111))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hallucination type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"dataset/rag_truth_span_test.json\", \"r\") as f:\n",
    "    test_data_span = json.load(f)\n",
    "with open(\"dataset/rag_truth_span_train.json\", \"r\") as f:\n",
    "    train_data_span = json.load(f)\n",
    "with open(\"dataset/rag_truth_span_dev.json\", \"r\") as f:\n",
    "    dev_data_span = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ref': 'The FBI charged a Philadelphia woman on Thursday with trying to travel overseas to fight for ISIS. She\\'s one of three women arrested this week on terror charges. Two New York women were also taken into custody. An FBI complaint cites numerous social media messages dating back to August 2013 that were sent by Keonna Thomas, 30, also known as \"Young Lioness\" and \"Fatayat Al Khilafah.\" One Twitter message said, \"If we truly knew the realities ... we all would be rushing to join our brothers in the front lines pray ALLAH accept us as shuhada [martyrs].\" Another said, \"When you\\'re a mujahid [violent jihadi fighter] your death becomes a wedding.\" The FBI said Thomas purchased an electronic visa to Turkey on March 23. Turkey is known as the easiest place from which to enter Syria and join ISIS. An ISIS manual advises recruits to buy round-trip tickets to vacation spots such as Spain and then purchase tickets for their real destination once they arrive overseas, the FBI said. On March 26, Thomas purchased a ticket to Barcelona, with a March 29 departure and an April 15 return to the United States, the complaint said. It\\'s not clear when or where she was arrested. She was charged with knowingly attempting to provide material support and resources to a designated foreign terrorist organization. She could be sentenced to 15 years in prison. On Thursday, Noelle Velentzas, 28, and her former roommate, Asia Siddiqui, 31, were arrested in New York and accused of planning to build an explosive device for attacks in the United States, federal prosecutors said. In the past 18 months, the Justice Department\\'s National Security Division has prosecuted or is prosecuting more than 30 cases of people attempting to travel abroad to join or provide support to terrorist groups. Of those cases, 18 allegedly involve support to ISIS. \"The terrorist threat is more decentralized, more diffuse, more complicated,\" Homeland Security Secretary Jeh Johnson told reporters Thursday. \"It involves the potential lone wolf actor, it involves the effective use of social media, the Internet.\"\\n',\n",
       " 'text': 'The FBI has charged a Philadelphia woman, Keonna Thomas, with trying to travel overseas to fight for ISIS. This follows the arrests of two New York women, Noelle Velentzas and Asia Siddiqui, who were accused of planning to build an explosive device for attacks in the United States. Thomas purchased an electronic visa to Turkey and a round-trip ticket to Barcelona, following the advice given in an ISIS manual for recruits. She has been charged with attempting to provide material support to a terrorist organisation and could face 15 years in prison.',\n",
       " 'labels': 0,\n",
       " 'hallucination_id': [],\n",
       " 'hallucination': {'hallucination_list': []},\n",
       " 'source': 'CNN/DM',\n",
       " 'model': 'gpt-4-0613',\n",
       " 'task_type': 'Summary',\n",
       " 'source_id': '15596'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_span[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Evident Baseless Info': 156, 'Evident Conflict': 30, 'Subtle Baseless Info': 49}\n",
      "{'Evident Conflict': 489, 'Evident Baseless Info': 465, 'Subtle Baseless Info': 95, 'Subtle Conflict': 5}\n",
      "{'Evident Conflict': 100, 'Evident Baseless Info': 117, 'Subtle Conflict': 11, 'Subtle Baseless Info': 16}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "hal_type_qa = defaultdict(lambda:0)\n",
    "hal_type_d2t = defaultdict(lambda:0)\n",
    "hal_type_sum = defaultdict(lambda:0)\n",
    "\n",
    "for d in test_data_span:\n",
    "    if d[\"hallucination_id\"] == []:\n",
    "        continue\n",
    "    hal_type = []\n",
    "    for hal_id in d[\"hallucination_id\"]:\n",
    "        hal_type.append(hal_id[\"label_type\"])\n",
    "        \n",
    "    if d[\"task_type\"] == \"QA\":\n",
    "        for hal in hal_type:\n",
    "            hal_type_qa[hal] += 1\n",
    "    elif d[\"task_type\"] == \"Data2txt\":\n",
    "        for hal in hal_type:\n",
    "            hal_type_d2t[hal] += 1\n",
    "    else:\n",
    "        for hal in hal_type:\n",
    "            hal_type_sum[hal] += 1\n",
    "print(dict(hal_type_qa))\n",
    "print(dict(hal_type_d2t))\n",
    "print(dict(hal_type_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Evident Conflict': 23, 'Evident Baseless Info': 63, 'Subtle Baseless Info': 18}\n",
      "{'Evident Conflict': 61, 'Evident Baseless Info': 73, 'Subtle Baseless Info': 19, 'Subtle Conflict': 2}\n",
      "{'Evident Conflict': 82, 'Subtle Conflict': 9, 'Evident Baseless Info': 86, 'Subtle Baseless Info': 6}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "hal_type_qa_imp = defaultdict(lambda:0)\n",
    "hal_type_d2t_imp = defaultdict(lambda:0)\n",
    "hal_type_sum_imp = defaultdict(lambda:0)\n",
    "\n",
    "for i in id_001 + id_011:\n",
    "    if test_data_span[i][\"hallucination_id\"]==[]:\n",
    "        continue\n",
    "    hal_type_imp = []\n",
    "    for hal_id in test_data_span[i][\"hallucination_id\"]:\n",
    "        hal_type_imp.append(hal_id[\"label_type\"])\n",
    "        \n",
    "    if test_data_span[i][\"task_type\"] == \"QA\":\n",
    "        for hal in hal_type_imp:\n",
    "            hal_type_qa_imp[hal] += 1\n",
    "    elif test_data_span[i][\"task_type\"] == \"Data2txt\":\n",
    "        for hal in hal_type_imp:\n",
    "            hal_type_d2t_imp[hal] += 1\n",
    "    else:\n",
    "        for hal in hal_type_imp:\n",
    "            hal_type_sum_imp[hal] += 1\n",
    "print(dict(hal_type_qa_imp))\n",
    "print(dict(hal_type_d2t_imp))\n",
    "print(dict(hal_type_sum_imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = []\n",
    "for i in id_011:\n",
    "    if test_data_span[i][\"task_type\"]!=\"QA\":\n",
    "        continue\n",
    "    \n",
    "    hal_type2 = []\n",
    "    for hal_id in test_data_span[i][\"hallucination_id\"]:\n",
    "        hal_type2.append(hal_id[\"label_type\"])\n",
    "    \n",
    "    if \"Evident Conflict\" in hal_type2:\n",
    "        sample.append(test_data_span[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ref': '{\\'question\\': \\'history of the word gemini\\', \\'passages\\': \"passage 1:The word “Gemini” is a Latin word for twins and it is one of the constellations that actually look like its name would suggest. The first known reference of the Gemini constellation was in Aristotle’s Meteorologica, over 300 years BC. He mentions that he observed an occulting a star in Gemini and speaks of observing Jupiter in conjunction with it.\\\\n\\\\npassage 2:Gemini History. The History of Gemini. As other signs in the zodiac, Gemini is not in the same position as the constellation of Gemini. In the zodiac, it follows Taurus and takes the third 30 degrees of the zodiacal circle. Gemini is a mutable sign that is preceding the summer, and as such, it announces change while ruling the time of year when Taurus spring has ended, and life on Earth is about to change.\\\\n\\\\npassage 3:Gemini Mythology The Story Behind the Gemini Zodiac Sign. The origins of some constellation myths are heavily debated. Gemini mythology, luckily, is pretty straightforward. By all accounts, the twins represented in Gemini mythology are Castor and Pollux of Greek mythology. They share the same mother, Leda (Greek mythology), but have different fathers. Castor\\'s father is Tyndarus, the King of Sparta, and Leda\\'s husband.\\\\n\\\\n\"}',\n",
       " 'text': 'Based on the given passages, we can gather that the word \"Gemini\" comes from the Latin language and refers to twins. It is also one of the constellations that resembles its name. The first known reference to the Gemini constellation was in Aristotle\\'s Meteorologica, around 300 years ago. The constellation represents the twins Castor and Pollux in Greek mythology.',\n",
       " 'labels': 1,\n",
       " 'hallucination_id': [{'start': 267,\n",
       "   'end': 287,\n",
       "   'text': 'around 300 years ago',\n",
       "   'meta': 'EVIDENT CONFLICT\\nOriginal: 300 years BC\\nGenerative: around 300 years ago',\n",
       "   'label_type': 'Evident Conflict',\n",
       "   'implicit_true': False,\n",
       "   'due_to_null': False}],\n",
       " 'hallucination': {'hallucination_list': ['around 300 years ago']},\n",
       " 'source': 'MARCO',\n",
       " 'model': 'mistral-7B-instruct',\n",
       " 'task_type': 'QA',\n",
       " 'source_id': '15540'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2 = []\n",
    "for i in id_101:\n",
    "    if test_data_span[i][\"task_type\"]!=\"Data2txt\":\n",
    "        continue\n",
    "    \n",
    "    hal_type2 = []\n",
    "    for hal_id in test_data_span[i][\"hallucination_id\"]:\n",
    "        hal_type2.append(hal_id[\"label_type\"])\n",
    "    \n",
    "    if \"Subtle Baseless Info\" in hal_type2 and \"Evident Baseless Info\" in hal_type2:\n",
    "        sample2.append(test_data_span[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ref': '{\\'name\\': \\'Finch & Fork\\', \\'address\\': \\'31 W Carrillo St\\', \\'city\\': \\'Santa Barbara\\', \\'state\\': \\'CA\\', \\'categories\\': \\'Breakfast & Brunch, American (New), Restaurants, American (Traditional), Nightlife, Bars\\', \\'hours\\': {\\'Monday\\': \\'17:30-23:0\\', \\'Tuesday\\': \\'17:0-21:0\\', \\'Wednesday\\': \\'17:0-21:0\\', \\'Thursday\\': \\'17:0-21:0\\', \\'Friday\\': \\'17:0-21:0\\', \\'Saturday\\': \\'17:0-21:0\\', \\'Sunday\\': \\'9:0-14:0\\'}, \\'attributes\\': {\\'BusinessParking\\': {\\'garage\\': True, \\'street\\': True, \\'validated\\': True, \\'lot\\': False, \\'valet\\': True}, \\'RestaurantsReservations\\': True, \\'OutdoorSeating\\': False, \\'WiFi\\': \\'free\\', \\'RestaurantsTakeOut\\': True, \\'RestaurantsGoodForGroups\\': True, \\'Music\\': False, \\'Ambience\\': {\\'romantic\\': False, \\'intimate\\': False, \\'classy\\': True, \\'hipster\\': False, \\'divey\\': False, \\'touristy\\': False, \\'trendy\\': False, \\'upscale\\': False, \\'casual\\': False}}, \\'business_stars\\': 4.0, \\'review_info\\': [{\\'review_stars\\': 5.0, \\'review_date\\': \\'2022-01-09 19:18:59\\', \\'review_text\\': \\'What a great brunch. A couple days ago my wife randomly decided she\\\\\\'d book a hotel in Santa Barbara for the weekend. She said she had already found a good spot for brunch Sunday morning. Usually I plan all the trips so she had a lot of pressure not to disappoint. And... she did not. Moral of the story: here we are now, just enjoyed a delicious breakfast burrito (her) and steak/eggs/frites (me). Most importantly the \"mimosa madness\" was served just the way I like it, just a splash of juice. This may have influenced this review :)\\\\nOur server Jamie was awesome and very hospitable. 5 stars for food, ambiance, and service. We\\\\\\'ll be back some day.\\'}, {\\'review_stars\\': 5.0, \\'review_date\\': \\'2021-12-24 05:45:27\\', \\'review_text\\': \\'main downside is that the food was overpriced. taste and quality of the food was great and service was also good. ambiance is nice, the restaurant is located in a hotel lobby.\\'}, {\\'review_stars\\': 5.0, \\'review_date\\': \\'2021-12-21 03:21:40\\', \\'review_text\\': \"The best bottomless brunch! $14 for the first mimosa, and $1 for every mimosa after that. \\\\n\\\\nWe came on a Sunday for brunch and we didn\\'t have to wait which was nice. The restaurant is inside a VERY nice hotel, and I was shocked at how cheap the menu is, given how nice the ambiance is. \\\\n\\\\nOur server Matthew was great. We were in SB for the day and he was giving us tips on what to do & where to go. He was very outgoing & kind, and the service was fast and on point. \\\\n\\\\nThe food was good as well, I got the eggs benedict and it was filling & delicious. The mimosas were BOMB and so cheap... we paid only $16 each for bottomless! They also have different flavors: orange, grapefruit, and poinsettia/cranberry which were all v tasty. \\\\n\\\\nDEFINITELY recommend this place to anyone looking for a good bottomless brunch!\"}]}',\n",
       " 'text': 'Finch & Fork is a breakfast and brunch restaurant located in the heart of Santa Barbara, within a luxury hotel. The restaurant offers a variety of dishes including breakfast burritos, steak, eggs, and frites, along with a selection of bottomless mimosas. According to customer reviews, the food is delicious, with generous portions, and the service is friendly and attentive. The ambiance is described as nice, with a classy and upscale atmosphere, despite being located in a hotel lobby. Some customers have noted that the prices are a bit high, but the quality of the food and service makes up for it. Finch & Fork is a popular spot for both locals and visitors, and is especially known for its bottomless brunch deals. Overall, this restaurant is a great choice for those looking for a tasty and satisfying breakfast or brunch experience in Santa Barbara.',\n",
       " 'labels': 1,\n",
       " 'hallucination_id': [{'start': 429,\n",
       "   'end': 448,\n",
       "   'text': 'upscale atmosphere,',\n",
       "   'meta': 'EVIDENT CONFLICT\\nOriginal: false for upscale\\nAIGC: with a[n] upscale atmosphere',\n",
       "   'label_type': 'Evident Conflict',\n",
       "   'implicit_true': False,\n",
       "   'due_to_null': False},\n",
       "  {'start': 622,\n",
       "   'end': 663,\n",
       "   'text': 'popular spot for both locals and visitors',\n",
       "   'meta': 'Original: No mention that this restaurant is a popular spot for locals and visitors. ',\n",
       "   'label_type': 'Evident Baseless Info',\n",
       "   'implicit_true': False,\n",
       "   'due_to_null': False},\n",
       "  {'start': 50,\n",
       "   'end': 88,\n",
       "   'text': 'located in the heart of Santa Barbara,',\n",
       "   'meta': 'LOW INTRO OF NEW INFO\\nNo mention of this information but may stand to be accurate. ',\n",
       "   'label_type': 'Subtle Baseless Info',\n",
       "   'implicit_true': True,\n",
       "   'due_to_null': False}],\n",
       " 'hallucination': {'hallucination_list': ['upscale atmosphere,',\n",
       "   'popular spot for both locals and visitors',\n",
       "   'located in the heart of Santa Barbara,']},\n",
       " 'source': 'Yelp',\n",
       " 'model': 'llama-2-70b-chat',\n",
       " 'task_type': 'Data2txt',\n",
       " 'source_id': '13601'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample3 = []\n",
    "for i in id_011:\n",
    "    if test_data_span[i][\"task_type\"]!=\"Summary\":\n",
    "        continue\n",
    "    \n",
    "    hal_type2 = []\n",
    "    for hal_id in test_data_span[i][\"hallucination_id\"]:\n",
    "        hal_type2.append(hal_id[\"label_type\"])\n",
    "    \n",
    "    if \"Subtle Baseless Info\" in hal_type2 or \"Evident Baseless Info\" in hal_type2:\n",
    "        sample3.append(test_data_span[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ref': 'A nuclear submarine being repaired at a Russian shipyard has caught on fire, according to a law enforcement source speaking to Russia\\'s state-run news agency ITAR-Tass. \"The submarine is in a dry dock,\" Tass reports, citing the source, and there is no ammunition on board. \"The rubber insulation between the submarine\\'s light and pressure hull is on fire,\" Tass reported. Russia\\'s RIA Novosti news agency says insulation caught on fire as welding work was being done on the submarine. Tass reported that the fire began on a sub in the Zvyozdochka shipyard in northwestern Russia. Zvyozdochka spokesman Yevgeny Gladyshev told the news agency that the sub had been undergoing repairs since November 2013. \"Nuclear fuel from the sub\\'s reactor has been unloaded,\" he reportedly said. \"There are no armaments or chemically active, dangerous substances, fissionable materials on it,\" Gladyshev said to Tass. \"The enterprise\\'s personnel left the premises when the submarine caught fire, no one has been injured. The fire presents no threat to people and the shipyard.\"\\n',\n",
       " 'text': 'A nuclear submarine being repaired in Russia caught fire due to accidental welding damage, causing an explosion that released radiation into the air. Four workers were killed in the incident and over 170 others were hospitalized. The cause of the explosion remains unknown but experts have suggested that a spark may have ignited a hydrogen leak. The damaged sub is currently being dismantled and decommissioned.',\n",
       " 'labels': 1,\n",
       " 'hallucination_id': [{'start': 91,\n",
       "   'end': 149,\n",
       "   'text': 'causing an explosion that released radiation into the air.',\n",
       "   'meta': 'HIGH INTRO OF NEW INFO\\nNo mention of an explosion. ',\n",
       "   'label_type': 'Evident Baseless Info',\n",
       "   'implicit_true': False,\n",
       "   'due_to_null': False},\n",
       "  {'start': 150,\n",
       "   'end': 346,\n",
       "   'text': 'Four workers were killed in the incident and over 170 others were hospitalized. The cause of the explosion remains unknown but experts have suggested that a spark may have ignited a hydrogen leak.',\n",
       "   'meta': 'HIGH INTRO OF NEW INFO\\nNo mention of these details. ',\n",
       "   'label_type': 'Evident Baseless Info',\n",
       "   'implicit_true': False,\n",
       "   'due_to_null': False},\n",
       "  {'start': 347,\n",
       "   'end': 412,\n",
       "   'text': 'The damaged sub is currently being dismantled and decommissioned.',\n",
       "   'meta': 'HIGH INTRO OF NEW INFO\\nNo mention of these details. ',\n",
       "   'label_type': 'Evident Baseless Info',\n",
       "   'implicit_true': False,\n",
       "   'due_to_null': False}],\n",
       " 'hallucination': {'hallucination_list': ['causing an explosion that released radiation into the air.',\n",
       "   'Four workers were killed in the incident and over 170 others were hospitalized. The cause of the explosion remains unknown but experts have suggested that a spark may have ignited a hydrogen leak.',\n",
       "   'The damaged sub is currently being dismantled and decommissioned.']},\n",
       " 'source': 'CNN/DM',\n",
       " 'model': 'mistral-7B-instruct',\n",
       " 'task_type': 'Summary',\n",
       " 'source_id': '15714'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample3[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"dataset/rag_truth_span_test.json\", \"r\") as f:\n",
    "    test_data_span = json.load(f)\n",
    "with open(\"dataset/rag_truth_span_train.json\", \"r\") as f:\n",
    "    train_data_span = json.load(f)\n",
    "with open(\"dataset/rag_truth_span_dev.json\", \"r\") as f:\n",
    "    dev_data_span = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ref': 'The FBI charged a Philadelphia woman on Thursday with trying to travel overseas to fight for ISIS. She\\'s one of three women arrested this week on terror charges. Two New York women were also taken into custody. An FBI complaint cites numerous social media messages dating back to August 2013 that were sent by Keonna Thomas, 30, also known as \"Young Lioness\" and \"Fatayat Al Khilafah.\" One Twitter message said, \"If we truly knew the realities ... we all would be rushing to join our brothers in the front lines pray ALLAH accept us as shuhada [martyrs].\" Another said, \"When you\\'re a mujahid [violent jihadi fighter] your death becomes a wedding.\" The FBI said Thomas purchased an electronic visa to Turkey on March 23. Turkey is known as the easiest place from which to enter Syria and join ISIS. An ISIS manual advises recruits to buy round-trip tickets to vacation spots such as Spain and then purchase tickets for their real destination once they arrive overseas, the FBI said. On March 26, Thomas purchased a ticket to Barcelona, with a March 29 departure and an April 15 return to the United States, the complaint said. It\\'s not clear when or where she was arrested. She was charged with knowingly attempting to provide material support and resources to a designated foreign terrorist organization. She could be sentenced to 15 years in prison. On Thursday, Noelle Velentzas, 28, and her former roommate, Asia Siddiqui, 31, were arrested in New York and accused of planning to build an explosive device for attacks in the United States, federal prosecutors said. In the past 18 months, the Justice Department\\'s National Security Division has prosecuted or is prosecuting more than 30 cases of people attempting to travel abroad to join or provide support to terrorist groups. Of those cases, 18 allegedly involve support to ISIS. \"The terrorist threat is more decentralized, more diffuse, more complicated,\" Homeland Security Secretary Jeh Johnson told reporters Thursday. \"It involves the potential lone wolf actor, it involves the effective use of social media, the Internet.\"\\n',\n",
       " 'text': 'The FBI has charged a Philadelphia woman, Keonna Thomas, with trying to travel overseas to fight for ISIS. This follows the arrests of two New York women, Noelle Velentzas and Asia Siddiqui, who were accused of planning to build an explosive device for attacks in the United States. Thomas purchased an electronic visa to Turkey and a round-trip ticket to Barcelona, following the advice given in an ISIS manual for recruits. She has been charged with attempting to provide material support to a terrorist organisation and could face 15 years in prison.',\n",
       " 'labels': 0,\n",
       " 'hallucination_id': [],\n",
       " 'hallucination': {'hallucination_list': []},\n",
       " 'source': 'CNN/DM',\n",
       " 'model': 'gpt-4-0613',\n",
       " 'task_type': 'Summary',\n",
       " 'source_id': '15596',\n",
       " 'sim_before': 0.9261488318443298}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_span[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'llama-2-13b-chat': 36, 'mistral-7B-instruct': 31, 'llama-2-7b-chat': 52, 'llama-2-70b-chat': 35, 'gpt-3.5-turbo-0613': 5, 'gpt-4-0613': 1}\n",
      "{'gpt-4-0613': 35, 'mistral-7B-instruct': 134, 'llama-2-7b-chat': 123, 'llama-2-13b-chat': 138, 'llama-2-70b-chat': 112, 'gpt-3.5-turbo-0613': 37}\n",
      "{'llama-2-13b-chat': 33, 'llama-2-70b-chat': 24, 'mistral-7B-instruct': 86, 'gpt-3.5-turbo-0613': 4, 'llama-2-7b-chat': 51, 'gpt-4-0613': 6}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "hal_model_qa = defaultdict(lambda:0)\n",
    "hal_model_d2t = defaultdict(lambda:0)\n",
    "hal_model_sum = defaultdict(lambda:0)\n",
    "\n",
    "for d in test_data_span:\n",
    "    if d[\"hallucination_id\"] == []:\n",
    "        continue\n",
    "        \n",
    "    if d[\"task_type\"] == \"QA\":\n",
    "        hal_model_qa[d[\"model\"]] += 1\n",
    "    elif d[\"task_type\"] == \"Data2txt\":\n",
    "        hal_model_d2t[d[\"model\"]] += 1\n",
    "    else:\n",
    "        hal_model_sum[d[\"model\"]] += 1\n",
    "print(dict(hal_model_qa))\n",
    "print(dict(hal_model_d2t))\n",
    "print(dict(hal_model_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'llama-2-13b-chat': 35, 'llama-2-7b-chat': 51, 'llama-2-70b-chat': 29, 'mistral-7B-instruct': 24, 'gpt-3.5-turbo-0613': 4}\n",
      "{'llama-2-70b-chat': 80, 'llama-2-13b-chat': 132, 'mistral-7B-instruct': 121, 'llama-2-7b-chat': 101, 'gpt-4-0613': 1}\n",
      "{'llama-2-13b-chat': 20, 'mistral-7B-instruct': 39, 'llama-2-7b-chat': 34, 'llama-2-70b-chat': 11}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "hal_model_qa_imp = defaultdict(lambda:0)\n",
    "hal_model_d2t_imp = defaultdict(lambda:0)\n",
    "hal_model_sum_imp = defaultdict(lambda:0)\n",
    "\n",
    "for i in id_011 + id_111:\n",
    "    d = test_data_span[i]\n",
    "    if d[\"hallucination_id\"] == []:\n",
    "        continue\n",
    "        \n",
    "    if d[\"task_type\"] == \"QA\":\n",
    "        hal_model_qa_imp[d[\"model\"]] += 1\n",
    "    elif d[\"task_type\"] == \"Data2txt\":\n",
    "        hal_model_d2t_imp[d[\"model\"]] += 1\n",
    "    else:\n",
    "        hal_model_sum_imp[d[\"model\"]] += 1\n",
    "print(dict(hal_model_qa_imp))\n",
    "print(dict(hal_model_d2t_imp))\n",
    "print(dict(hal_model_sum_imp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
