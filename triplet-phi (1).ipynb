{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"rag_truth_train2.json\", \"r\") as f:\n",
    "    train_data = json.load(f)\n",
    "with open(\"rag_truth_dev.json\", \"r\") as f:\n",
    "    dev_data = json.load(f)\n",
    "with open(\"rag_truth_test.json\", \"r\") as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefixをつける\n",
    "def add_prefix(data):\n",
    "    for d in data:\n",
    "        d[\"text\"] = \"Please judge the following statement as true or false based on the references above: \" + d[\"text\"]\n",
    "    return data\n",
    "\n",
    "train_data = add_prefix(train_data)\n",
    "dev_data = add_prefix(dev_data)\n",
    "test_data = add_prefix(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_type: QA, Data2txt, Summary\n",
    "task_name = \"Summary\"\n",
    "train_data = [d for d in train_data if d[\"task_type\"] == task_name]\n",
    "dev_data = [d for d in dev_data if d[\"task_type\"] == task_name]\n",
    "test_data = [d for d in test_data if d[\"task_type\"] == task_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def create_trip(data, id_list):\n",
    "    trip = []\n",
    "    for id in id_list:\n",
    "        num = 0\n",
    "        no_hal = []\n",
    "        has_hal = []\n",
    "        for d in data:\n",
    "            if num == 6:\n",
    "                num = 0\n",
    "                if no_hal == [] or has_hal == []:\n",
    "                    break\n",
    "                '''\n",
    "                for no in no_hal:\n",
    "                    for has in has_hal:\n",
    "                        trip.append({\"anchor\":ref,\"positive\": no, \"negative\": has, \"labels\":[0,1]})\n",
    "                '''\n",
    "                # シャッフル\n",
    "                random.seed(id)\n",
    "                no_hal = random.sample(no_hal, len(no_hal))\n",
    "                has_hal = random.sample(has_hal, len(has_hal))\n",
    "                \n",
    "                if len(no_hal)==1 or len(no_hal)==5:\n",
    "                    trip.append({\"anchor\":ref,\"positive\": no_hal[0], \"negative\": has_hal[0], \"labels\":[0,1]})\n",
    "                elif len(no_hal)==2 or len(no_hal)==4:\n",
    "                    trip.append({\"anchor\":ref,\"positive\": no_hal[0], \"negative\": has_hal[0], \"labels\":[0,1]})\n",
    "                    trip.append({\"anchor\":ref,\"positive\": no_hal[1], \"negative\": has_hal[1], \"labels\":[0,1]})\n",
    "                elif len(no_hal)==3:\n",
    "                    trip.append({\"anchor\":ref,\"positive\": no_hal[0], \"negative\": has_hal[0], \"labels\":[0,1]})\n",
    "                    trip.append({\"anchor\":ref,\"positive\": no_hal[1], \"negative\": has_hal[1], \"labels\":[0,1]})\n",
    "                    trip.append({\"anchor\":ref,\"positive\": no_hal[2], \"negative\": has_hal[2], \"labels\":[0,1]})\n",
    "                no_hal = []\n",
    "                has_hal = []\n",
    "                break\n",
    "            elif d[\"source_id\"] == id:\n",
    "                num +=1\n",
    "                ref = d[\"ref\"]\n",
    "                if d[\"labels\"] == 0:\n",
    "                    no_hal.append(d[\"text\"])\n",
    "                else:\n",
    "                    has_hal.append(d[\"text\"])\n",
    "        if num == 6:\n",
    "            if len(no_hal)==1 or len(no_hal)==5:\n",
    "                trip.append({\"anchor\":ref,\"positive\": no_hal[0], \"negative\": has_hal[0], \"labels\":[0,1]})\n",
    "            elif len(no_hal)==2 or len(no_hal)==4:\n",
    "                trip.append({\"anchor\":ref,\"positive\": no_hal[0], \"negative\": has_hal[0], \"labels\":[0,1]})\n",
    "                trip.append({\"anchor\":ref,\"positive\": no_hal[1], \"negative\": has_hal[1], \"labels\":[0,1]})\n",
    "            elif len(no_hal)==3:\n",
    "                trip.append({\"anchor\":ref,\"positive\": no_hal[0], \"negative\": has_hal[0], \"labels\":[0,1]})\n",
    "                trip.append({\"anchor\":ref,\"positive\": no_hal[1], \"negative\": has_hal[1], \"labels\":[0,1]})\n",
    "                trip.append({\"anchor\":ref,\"positive\": no_hal[2], \"negative\": has_hal[2], \"labels\":[0,1]})\n",
    "    return trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2305 210 450\n"
     ]
    }
   ],
   "source": [
    "train_id = [d[\"source_id\"] for d in train_data]\n",
    "train_id = list(set(train_id))\n",
    "dev_id = [d[\"source_id\"] for d in dev_data]\n",
    "dev_id = list(set(dev_id))\n",
    "test_id = [d[\"source_id\"] for d in test_data]\n",
    "test_id = list(set(test_id))\n",
    "print(len(train_id), len(dev_id), len(test_id))\n",
    "train_trip = create_trip(train_data, train_id)\n",
    "dev_trip = create_trip(dev_data, dev_id)\n",
    "test_trip = create_trip(test_data, test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3760, 337, 633)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_trip), len(dev_trip), len(test_trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['anchor', 'positive', 'negative', 'labels'],\n",
       "        num_rows: 3760\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['anchor', 'positive', 'negative', 'labels'],\n",
       "        num_rows: 337\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['anchor', 'positive', 'negative', 'labels'],\n",
       "        num_rows: 633\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.DataFrame(train_trip)\n",
    "dev_df = pd.DataFrame(dev_trip)\n",
    "test_df = pd.DataFrame(test_trip)\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "dev_ds = Dataset.from_pandas(dev_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "\n",
    "tri_raw_datasets = DatasetDict({\"train\": train_ds, \"dev\": dev_ds, \"test\": test_ds})\n",
    "tri_raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "#tri_tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/RoBERTa-base\")\n",
    "tri_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anchor': '{\\'name\\': \\'Santa Barbara Chicken Ranch\\', \\'address\\': \\'2618 De La Vina St\\', \\'city\\': \\'Santa Barbara\\', \\'state\\': \\'CA\\', \\'categories\\': \\'Health & Medical, Restaurants, Mexican, Cannabis Clinics, Barbeque\\', \\'hours\\': {\\'Monday\\': \\'11:0-22:0\\', \\'Tuesday\\': \\'11:0-22:0\\', \\'Wednesday\\': \\'11:0-22:0\\', \\'Thursday\\': \\'11:0-22:0\\', \\'Friday\\': \\'11:0-22:0\\', \\'Saturday\\': \\'11:0-22:0\\', \\'Sunday\\': \\'11:0-22:0\\'}, \\'attributes\\': {\\'BusinessParking\\': {\\'garage\\': False, \\'street\\': False, \\'validated\\': False, \\'lot\\': True, \\'valet\\': False}, \\'RestaurantsReservations\\': False, \\'OutdoorSeating\\': True, \\'WiFi\\': \\'no\\', \\'RestaurantsTakeOut\\': True, \\'RestaurantsGoodForGroups\\': True, \\'Music\\': None, \\'Ambience\\': {\\'romantic\\': False, \\'intimate\\': False, \\'touristy\\': False, \\'hipster\\': False, \\'divey\\': False, \\'classy\\': False, \\'trendy\\': False, \\'upscale\\': False, \\'casual\\': True}}, \\'business_stars\\': 4.0, \\'review_info\\': [{\\'review_stars\\': 5.0, \\'review_date\\': \\'2021-12-08 19:15:29\\', \\'review_text\\': \"If you\\'re not from town you might want to be sure to check this place out. Otherwise you likely are familiar already. Wood fire grill and homemade salsa and priced how I recall things 15 years ago. They deliver and open at 11 am sharp. You will probably wait a bit if you don\\'t call ahead.\"}, {\\'review_stars\\': 5.0, \\'review_date\\': \\'2021-11-23 11:06:15\\', \\'review_text\\': \\'This place easily gets five stars for delicious food, low cost, good portions, and quick service. \\\\xa0Our family had the chicken plate a tri-tip burrito, and two drinks. The kids can be a bit picky about chicken, but they gobbled this Mesquite BBQ. They both put the chicken on the included flour tortillas with some Spanish rice, pinto beans, and pico. The tri-tip burrito was great; well stacked and very flavorful. \\\\xa0After a couple days of vacationing in SB with expensive but mediocre food, this place was awesome. \\\\xa0Would definitely come again.\\'}, {\\'review_stars\\': 5.0, \\'review_date\\': \\'2021-10-15 00:27:53\\', \\'review_text\\': \\'Love this place! Just found this week and have gone twice. Their burritos are delish, shredded chicken is fresh and amazing! Well priced and well worth the trip!!!\\'}]}',\n",
       " 'positive': \"Please judge the following statement as true or false based on the references above: Santa Barbara Chicken Ranch is a local business located at 2618 De La Vina St in Santa Barbara, CA. The establishment offers a variety of services and cuisines, including Health & Medical, Restaurants, Mexican, Cannabis Clinics, and Barbeque. Operating hours are from 11:00 am to 10:00 pm every day of the week. The business has a parking lot available for customers. Reservations are not accepted, but outdoor seating is provided. The restaurant offers takeout services and is suitable for groups. Unfortunately, there is no WiFi available on the premises.\\n\\nCustomers have left positive reviews about Santa Barbara Chicken Ranch. One reviewer mentioned that the food is delicious, reasonably priced, and served in generous portions, with quick service. Another reviewer praised the fresh and amazing shredded chicken in the burritos, stating that the prices are affordable and the restaurant is worth visiting. A third reviewer highlighted the wood fire grill and homemade salsa, as well as the nostalgic pricing. They also mentioned that the restaurant delivers and opens promptly at 11 am, although there may be a wait if one doesn't call ahead.\\n\\nOverall, Santa Barbara Chicken Ranch has received an average rating of 4.0 stars from customers, who appreciate the tasty food, reasonable prices, and friendly service.\",\n",
       " 'negative': 'Please judge the following statement as true or false based on the references above: Santa Barbara Chicken Ranch is a restaurant located in the heart of Santa Barbara, California. The business offers a variety of cuisines, including health and medical services, Mexican food, barbecue, and cannabis clinics. The hours of operation are Monday through Sunday, from 11:00 am to 11:00 pm. The restaurant has outdoor seating and provides takeout options.\\n\\nThe restaurant has received positive reviews from its customers. One customer highly recommended the place, stating that it is a must-visit for anyone who is not from town. Another customer praised the quality of the food, which they described as delicious, low-cost, and served in generous portions. A third customer also gave high praise for the food, specifically mentioning the mesquite BBQ chicken and the tri-tip burrito. Overall, customers seem to appreciate the affordable prices and friendly service at Santa Barbara Chicken Ranch.',\n",
       " 'labels': [0, 1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_raw_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "def tri_tokenize_function(examples):\n",
    "    anchor = tri_tokenizer(examples[\"anchor\"], truncation=True,max_length=512)\n",
    "    positive = tri_tokenizer(examples[\"positive\"], truncation=True,max_length=512)\n",
    "    negative = tri_tokenizer(examples[\"negative\"], truncation=True,max_length=512)\n",
    "\n",
    "    return {\n",
    "        \"anchor_input_ids\": anchor[\"input_ids\"],\n",
    "        \"anchor_attention_mask\": anchor[\"attention_mask\"],\n",
    "        \"positive_input_ids\": positive[\"input_ids\"],\n",
    "        \"positive_attention_mask\": positive[\"attention_mask\"],\n",
    "        \"negative_input_ids\": negative[\"input_ids\"],\n",
    "        \"negative_attention_mask\": negative[\"attention_mask\"],\n",
    "    }\n",
    "\n",
    "tri_tokenized_datasets = tri_raw_datasets.map(tri_tokenize_function, batched=True)\n",
    "tri_tokenized_datasets = tri_tokenized_datasets.remove_columns([\"anchor\", \"positive\", \"negative\"])\n",
    "#tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tri_tokenized_datasets.set_format(\"torch\")\n",
    "tri_data_collator = DataCollatorWithPadding(tokenizer=tri_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "class CustomDataCollator(DataCollatorWithPadding):\n",
    "    def __call__(self, features):\n",
    "        # features の例: [{'anchor_input_ids': ..., 'anchor_attention_mask': ..., ...}, ...]\n",
    "        \n",
    "        # データのリストを作成\n",
    "        anchor_ids = [x['anchor_input_ids'].clone().detach() for x in features]\n",
    "        positive_ids = [x['positive_input_ids'].clone().detach() for x in features]\n",
    "        negative_ids = [x['negative_input_ids'].clone().detach() for x in features]\n",
    "        \n",
    "        anchor_mask = [x['anchor_attention_mask'].clone().detach() for x in features]\n",
    "        positive_mask = [x['positive_attention_mask'].clone().detach() for x in features]\n",
    "        negative_mask = [x['negative_attention_mask'].clone().detach() for x in features]\n",
    "        \n",
    "        # パディング処理\n",
    "        anchor_ids = pad_sequence(anchor_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
    "        positive_ids = pad_sequence(positive_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
    "        negative_ids = pad_sequence(negative_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
    "        \n",
    "        anchor_mask = pad_sequence(anchor_mask, batch_first=True, padding_value=0)\n",
    "        positive_mask = pad_sequence(positive_mask, batch_first=True, padding_value=0)\n",
    "        negative_mask = pad_sequence(negative_mask, batch_first=True, padding_value=0)\n",
    "\n",
    "        # ラベルを作成\n",
    "        labels = [x['labels'] for x in features]\n",
    "        \n",
    "        \n",
    "        # バッチ辞書を作成\n",
    "        batch = {\n",
    "            \"input_ids\": [anchor_ids, positive_ids, negative_ids],\n",
    "            \"attention_mask\": [anchor_mask, positive_mask, negative_mask],\n",
    "            \"labels\": labels\n",
    "        }\n",
    "        \n",
    "        return batch\n",
    "\n",
    "\n",
    "tri_data_collator = CustomDataCollator(tokenizer=tri_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "#base_model = AutoModel.from_pretrained(\"FacebookAI/RoBERTa-base\")\n",
    "base_model = AutoModel.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\")\n",
    "#base_model = AutoModel.from_pretrained(\"vinai/bertweet-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 使う装置\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "base_model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers.modeling_outputs import ModelOutput\n",
    "import os\n",
    "\n",
    "\n",
    "class TripletModel(nn.Module):\n",
    "    def __init__(self, base_model, loss_function, question_encoder=None, generator=None):\n",
    "        super(TripletModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        #self.triplet_loss_fn = nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(base_model.config.hidden_size * 2, 2)  # ラベル予測用の分類層\n",
    "        # self.classification_loss_fn = nn.CrossEntropyLoss()  # ラベル予測の損失関数\n",
    "        self.loss_function = loss_function\n",
    "        self.question_encoder = question_encoder\n",
    "        self.generator = generator\n",
    "        #self.alpha = alpha\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask = None,\n",
    "        labels = None,\n",
    "    ):\n",
    "        \n",
    "        anchor_input_ids = input_ids[0]\n",
    "        positive_input_ids = input_ids[1]\n",
    "        negative_input_ids = input_ids[2]\n",
    "        anchor_attention_mask = attention_mask[0]\n",
    "        positive_attention_mask = attention_mask[1]\n",
    "        negative_attention_mask = attention_mask[2]\n",
    "\n",
    "\n",
    "        anchor_output = self.base_model(input_ids=anchor_input_ids, attention_mask=anchor_attention_mask,return_dict=True)[0][:,-1,:]\n",
    "        positive_output = self.base_model(input_ids=positive_input_ids, attention_mask=positive_attention_mask,return_dict=True)[0][:,-1,:]\n",
    "        negative_output = self.base_model(input_ids=negative_input_ids, attention_mask=negative_attention_mask,return_dict=True)[0][:,-1,:]\n",
    "\n",
    "        #anchor_output = anchor_output.mean(dim=1)\n",
    "        #positive_output = positive_output.mean(dim=1)\n",
    "        #negative_output = negative_output.mean(dim=1)\n",
    "\n",
    "        anchor_output = self.dropout(anchor_output)\n",
    "        positive_output = self.dropout(positive_output)\n",
    "        negative_output = self.dropout(negative_output)\n",
    "\n",
    "        # ラベル予測の出力\n",
    "        positive_logits = self.classifier(torch.cat([anchor_output, positive_output], dim=1))\n",
    "        negative_logits = self.classifier(torch.cat([anchor_output, negative_output], dim=1))\n",
    "\n",
    "        classification_loss, triplet_loss=self.loss_function(anchor_output, positive_output, negative_output, positive_logits, negative_logits)\n",
    "        loss = classification_loss + triplet_loss\n",
    "        \n",
    "        #return ModelOutput(logits=[positive_logits, negative_logits], loss=loss,classification_loss=classification_loss,triplet_loss=triplet_loss)\n",
    "        return ModelOutput(logits=[positive_logits, negative_logits],loss=loss)\n",
    "\n",
    "    def save_pretrained(self, save_directory):\n",
    "        \"\"\"\n",
    "        モデル全体とサブモジュールを保存するカスタムメソッド\n",
    "        \"\"\"\n",
    "        os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "        # サブモジュールの保存\n",
    "        if self.question_encoder is not None:\n",
    "            self.question_encoder.save_pretrained(os.path.join(save_directory, \"question_encoder\"))\n",
    "        if self.generator is not None:\n",
    "            self.generator.save_pretrained(os.path.join(save_directory, \"generator\"))\n",
    "\n",
    "        # モデル全体の重みを保存\n",
    "        torch.save(self.state_dict(), os.path.join(save_directory, \"pytorch_model.bin\"))\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, save_directory):\n",
    "        \"\"\"\n",
    "        保存済みモデルをロードするカスタムメソッド\n",
    "        \"\"\"\n",
    "        question_encoder = None\n",
    "        generator = None\n",
    "\n",
    "        # サブモジュールのロード\n",
    "        if os.path.exists(os.path.join(save_directory, \"question_encoder\")):\n",
    "            question_encoder = AutoModel.from_pretrained(os.path.join(save_directory, \"question_encoder\"))\n",
    "        if os.path.exists(os.path.join(save_directory, \"generator\")):\n",
    "            generator = AutoModel.from_pretrained(os.path.join(save_directory, \"generator\"))\n",
    "\n",
    "        # モデル全体の重みをロード\n",
    "        model = cls(question_encoder=question_encoder, generator=generator)\n",
    "        model.load_state_dict(torch.load(os.path.join(save_directory, \"pytorch_model.bin\")))\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "clas_list = []\n",
    "trip_list = []\n",
    "def triplet_loss(anchor_output, positive_output, negative_output, positive_logits, negative_logits):\n",
    "    # ラベル予測の損失計算\n",
    "    positive_targets = torch.zeros(positive_output.size(0), dtype=torch.long).to(device)  # ラベル1 (positive)\n",
    "    negative_targets = torch.ones(negative_output.size(0), dtype=torch.long).to(device)\n",
    "    positive_loss = nn.CrossEntropyLoss()(positive_logits, positive_targets)\n",
    "    negative_loss = nn.CrossEntropyLoss()(negative_logits, negative_targets)\n",
    "\n",
    "    # ラベル予測の損失を平均\n",
    "    classification_loss = (positive_loss + negative_loss) / 2.0\n",
    "\n",
    "    # トリプレット損失の計算\n",
    "    #triplet_loss = nn.TripletMarginLoss(margin=1, p=2)(anchor_output, positive_output, negative_output)\n",
    "    triplet_loss_fn = (nn.TripletMarginWithDistanceLoss(margin=1.5,distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y)))\n",
    "    triplet_loss = triplet_loss_fn(anchor_output, positive_output, negative_output)\n",
    "    # 最終損失\n",
    "    total_loss = classification_loss + triplet_loss \n",
    "    #return total_loss\n",
    "    trip_list.append(triplet_loss)\n",
    "    clas_list.append(classification_loss)\n",
    "    return classification_loss, triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "# negativeがhalluでlabelが1\n",
    "def compute_tri_metrics(eval_pred):\n",
    "    #print(\"aa\")\n",
    "    # モデルの出力から損失と logits を取得\n",
    "    logits,labels= eval_pred\n",
    "    \n",
    "    # ロジットのサイズに合わせて推論を行う\n",
    "    positive_logits = torch.tensor(logits[0])\n",
    "    negative_logits = torch.tensor(logits[1])\n",
    "    #positive_logits = torch.tensor(logits[0][0])\n",
    "    #negative_logits = torch.tensor(logits[0][1])\n",
    "\n",
    "\n",
    "\n",
    "    # ラベル予測\n",
    "    positive_preds = torch.argmax(positive_logits, dim=1)\n",
    "    negative_preds = torch.argmax(negative_logits, dim=1)\n",
    "\n",
    "    # 正解と予測ラベルの一致数\n",
    "    correct_positive = (positive_preds == 0).sum().item()\n",
    "    correct_negative = (negative_preds == 1).sum().item()\n",
    "    \n",
    "    # ラベルの数\n",
    "    total_samples = positive_preds.size(0) + negative_preds.size(0)\n",
    "    \n",
    "    # PositiveとNegativeの予測数\n",
    "    positive_preds_num = (positive_preds == 1).sum().item()\n",
    "    negative_preds_num = (negative_preds == 1).sum().item()\n",
    "    positive_num = positive_preds.size(0)\n",
    "    negative_num = negative_preds.size(0)\n",
    "\n",
    "    #print(negative_preds_num,positive_preds_num,negative_num)\n",
    "\n",
    "    # Precision, Recall, F1の計算\n",
    "    precision = negative_preds_num / (positive_preds_num + negative_preds_num) if (positive_preds_num + negative_preds_num) > 0 else 0\n",
    "    recall = negative_preds_num / negative_num if negative_num > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    # 平均損失と正解率の計算\n",
    "    #avg_loss = loss.item() if loss is not None else 0\n",
    "    accuracy = (correct_positive + correct_negative) / total_samples\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"recall\": recall,\n",
    "        \"precision\": precision,\n",
    "        \"f1\": f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer, DataCollatorWithPadding\n",
    "import torch\n",
    "from models import TripletModel\n",
    "\n",
    "\"\"\"\n",
    "base_model = AutoModel.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\")\n",
    "# モデルとトークナイザーを読み込む\n",
    "name = \"./1224_triplet\"\n",
    "tri_model = TripletModel.from_pretrained(base_model, triplet_loss, name)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "\n",
    "# 使う装置\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "tri_model.to(device)\n",
    "\"\"\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"steps\",  \n",
    "    save_steps=10000,\n",
    "    learning_rate=1e-6,# 1e-6\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    fp16 = True,\n",
    "    gradient_accumulation_steps=12,\n",
    "    logging_dir=\"./logs\",\n",
    "    remove_unused_columns=False,\n",
    "    report_to=\"tensorboard\",\n",
    "    optim=\"adafactor\",\n",
    ")\n",
    "\n",
    "tri_model = TripletModel(base_model, triplet_loss)\n",
    "#triplet_loss_logger = TripletLossLogger()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=tri_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tri_tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tri_tokenized_datasets[\"dev\"],\n",
    "    data_collator=tri_data_collator,\n",
    "    tokenizer=tri_tokenizer,\n",
    "    compute_metrics=compute_tri_metrics,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160' max='780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160/780 16:03 < 1:02:59, 0.16 it/s, Epoch 2.03/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.988000</td>\n",
       "      <td>1.565921</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.692878</td>\n",
       "      <td>0.676558</td>\n",
       "      <td>0.699387</td>\n",
       "      <td>0.687783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.488800</td>\n",
       "      <td>1.380101</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.725519</td>\n",
       "      <td>0.816024</td>\n",
       "      <td>0.690955</td>\n",
       "      <td>0.748299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(eval_dataset=tri_tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dev_task(name):\n",
    "    dev_data2 = [d for d in test_data if d[\"task_type\"] == name]\n",
    "    dev_id2 = [d[\"source_id\"] for d in dev_data2]\n",
    "    dev_id2 = list(set(dev_id2))\n",
    "    dev_trip2 = create_trip(dev_data2, dev_id2)\n",
    "    dev_df2 = pd.DataFrame(dev_trip2)\n",
    "    dev_ds2 = Dataset.from_pandas(dev_df2)\n",
    "    tri_tokenized_datasets_task = dev_ds2.map(tri_tokenize_function, batched=True)\n",
    "    tri_tokenized_datasets_task = tri_tokenized_datasets_task.remove_columns([\"anchor\", \"positive\", \"negative\"])\n",
    "    tri_tokenized_datasets_task.set_format(\"torch\")\n",
    "    return tri_tokenized_datasets_task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883c376394664bc491502950313e8487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev_qa = create_dev_task(\"QA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5213183760643005,\n",
       " 'eval_model_preparation_time': 0.0039,\n",
       " 'eval_accuracy': 0.8966666666666666,\n",
       " 'eval_recall': 0.92,\n",
       " 'eval_precision': 0.8789808917197452,\n",
       " 'eval_f1': 0.8990228013029316,\n",
       " 'eval_runtime': 9.4958,\n",
       " 'eval_samples_per_second': 15.796,\n",
       " 'eval_steps_per_second': 4.002}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=dev_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9811b97fd341318fbab03e3eaf2a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/291 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev_d2t = create_dev_task(\"Data2txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9073538780212402,\n",
       " 'eval_model_preparation_time': 0.0039,\n",
       " 'eval_accuracy': 0.7852233676975945,\n",
       " 'eval_recall': 0.7491408934707904,\n",
       " 'eval_precision': 0.8074074074074075,\n",
       " 'eval_f1': 0.7771836007130126,\n",
       " 'eval_runtime': 19.65,\n",
       " 'eval_samples_per_second': 14.809,\n",
       " 'eval_steps_per_second': 3.715}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=dev_d2t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1443d5c65b456d98f25c4a2d4e311d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/192 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev_sum = create_dev_task(\"Summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.1023415327072144,\n",
       " 'eval_model_preparation_time': 0.0039,\n",
       " 'eval_accuracy': 0.71875,\n",
       " 'eval_recall': 0.65625,\n",
       " 'eval_precision': 0.75,\n",
       " 'eval_f1': 0.7,\n",
       " 'eval_runtime': 12.0214,\n",
       " 'eval_samples_per_second': 15.971,\n",
       " 'eval_steps_per_second': 3.993}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=dev_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニング後にモデルを保存\n",
    "# トレーニング後にモデルを保存\n",
    "name = \"./1228_triplet\"\n",
    "trainer.save_model(name)\n",
    "trainer.save_state()\n",
    "tri_model.save_pretrained(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 26 00:10:58 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA H100                    On  | 00000000:84:00.0 Off |                    0 |\n",
      "| N/A   29C    P0             151W / 699W |  15370MiB / 95830MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA H100                    On  | 00000000:E4:00.0 Off |                    0 |\n",
      "| N/A   26C    P0             152W / 699W |  15422MiB / 95830MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A   3486749      C   /home/3/uw03923/nlp/bin/python3           15356MiB |\n",
      "|    1   N/A  N/A   3486749      C   /home/3/uw03923/nlp/bin/python3           15408MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache() \n",
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
