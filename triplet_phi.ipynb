{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"dataset/rag_truth_train.json\", \"r\") as f:\n",
    "    train_data = json.load(f)\n",
    "with open(\"dataset/rag_truth_dev.json\", \"r\") as f:\n",
    "    dev_data = json.load(f)\n",
    "with open(\"dataset/rag_truth_test.json\", \"r\") as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prefix(data):\n",
    "    for d in data:\n",
    "        d[\"text\"] = \"Please judge the following statement whether it includes hallucination or not based on the references above: \" + d[\"text\"]\n",
    "    return data\n",
    "\n",
    "train_data = add_prefix(train_data)\n",
    "dev_data = add_prefix(dev_data)\n",
    "test_data = add_prefix(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_type: QA, Data2txt, Summary\n",
    "task_name = \"Summary\"\n",
    "train_data = [d for d in train_data if d[\"task_type\"] == task_name]\n",
    "dev_data = [d for d in dev_data if d[\"task_type\"] == task_name]\n",
    "test_data = [d for d in test_data if d[\"task_type\"] == task_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def create_trip(data, id_list):\n",
    "    trip = []\n",
    "    for id in id_list:\n",
    "        num = 0\n",
    "        no_hal = []\n",
    "        has_hal = []\n",
    "        for d in data:\n",
    "            if num == 6:\n",
    "                num = 0\n",
    "                if no_hal == [] or has_hal == []:\n",
    "                    break\n",
    "                # shuffle\n",
    "                random.seed(id) # change seed\n",
    "                no_hal = random.sample(no_hal, len(no_hal))\n",
    "                has_hal = random.sample(has_hal, len(has_hal))\n",
    "                \n",
    "                if len(no_hal)==1 or len(no_hal)==5:\n",
    "                    trip.append({\"anchor\":ref,\"positive\": no_hal[0], \"negative\": has_hal[0], \"labels\": 0}) # labels are dummy \n",
    "                elif len(no_hal)==2 or len(no_hal)==4:\n",
    "                    trip.append({\"anchor\":ref,\"positive\": no_hal[0], \"negative\": has_hal[0], \"labels\": 0})\n",
    "                    trip.append({\"anchor\":ref,\"positive\": no_hal[1], \"negative\": has_hal[1], \"labels\": 0})\n",
    "                elif len(no_hal)==3:\n",
    "                    trip.append({\"anchor\":ref,\"positive\": no_hal[0], \"negative\": has_hal[0], \"labels\": 0})\n",
    "                    trip.append({\"anchor\":ref,\"positive\": no_hal[1], \"negative\": has_hal[1], \"labels\": 0})\n",
    "                    trip.append({\"anchor\":ref,\"positive\": no_hal[2], \"negative\": has_hal[2], \"labels\": 0})\n",
    "                no_hal = []\n",
    "                has_hal = []\n",
    "                break\n",
    "            elif d[\"source_id\"] == id:\n",
    "                num +=1\n",
    "                ref = d[\"ref\"]\n",
    "                if d[\"labels\"] == 0:\n",
    "                    no_hal.append(d[\"text\"])\n",
    "                else: #hallucination\n",
    "                    has_hal.append(d[\"text\"])\n",
    "        if num == 6:\n",
    "            if len(no_hal)==1 or len(no_hal)==5:\n",
    "                trip.append({\"anchor\":ref,\"positive\": no_hal[0], \"negative\": has_hal[0], \"labels\": 0})\n",
    "            elif len(no_hal)==2 or len(no_hal)==4:\n",
    "                trip.append({\"anchor\":ref,\"positive\": no_hal[0], \"negative\": has_hal[0], \"labels\": 0})\n",
    "                trip.append({\"anchor\":ref,\"positive\": no_hal[1], \"negative\": has_hal[1], \"labels\": 0})\n",
    "            elif len(no_hal)==3:\n",
    "                trip.append({\"anchor\":ref,\"positive\": no_hal[0], \"negative\": has_hal[0], \"labels\": 0})\n",
    "                trip.append({\"anchor\":ref,\"positive\": no_hal[1], \"negative\": has_hal[1], \"labels\": 0})\n",
    "                trip.append({\"anchor\":ref,\"positive\": no_hal[2], \"negative\": has_hal[2], \"labels\": 0})\n",
    "    return trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2305 210 450\n"
     ]
    }
   ],
   "source": [
    "train_id = [d[\"source_id\"] for d in train_data]\n",
    "train_id = list(set(train_id))\n",
    "dev_id = [d[\"source_id\"] for d in dev_data]\n",
    "dev_id = list(set(dev_id))\n",
    "test_id = [d[\"source_id\"] for d in test_data]\n",
    "test_id = list(set(test_id))\n",
    "print(len(train_id), len(dev_id), len(test_id))\n",
    "train_trip = create_trip(train_data, train_id)\n",
    "dev_trip = create_trip(dev_data, dev_id)\n",
    "test_trip = create_trip(test_data, test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3760, 337, 633)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_trip), len(dev_trip), len(test_trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['anchor', 'positive', 'negative', 'labels'],\n",
       "        num_rows: 3760\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['anchor', 'positive', 'negative', 'labels'],\n",
       "        num_rows: 337\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['anchor', 'positive', 'negative', 'labels'],\n",
       "        num_rows: 633\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.DataFrame(train_trip)\n",
    "dev_df = pd.DataFrame(dev_trip)\n",
    "test_df = pd.DataFrame(test_trip)\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "dev_ds = Dataset.from_pandas(dev_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "\n",
    "tri_raw_datasets = DatasetDict({\"train\": train_ds, \"dev\": dev_ds, \"test\": test_ds})\n",
    "tri_raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tri_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anchor': '{\\'name\\': \\'Meet Up Chinese Cuisine\\', \\'address\\': \\'2251 Las Positas Rd\\', \\'city\\': \\'Santa Barbara\\', \\'state\\': \\'CA\\', \\'categories\\': \\'Szechuan, Chinese, Nightlife, Karaoke, Asian Fusion, Restaurants\\', \\'hours\\': {\\'Monday\\': \\'11:0-22:0\\', \\'Tuesday\\': \\'11:0-22:0\\', \\'Wednesday\\': \\'11:0-22:0\\', \\'Thursday\\': \\'11:0-22:0\\', \\'Friday\\': \\'11:0-22:0\\', \\'Saturday\\': \\'11:0-22:0\\', \\'Sunday\\': \\'11:0-22:0\\'}, \\'attributes\\': {\\'BusinessParking\\': {\\'garage\\': False, \\'street\\': True, \\'validated\\': False, \\'lot\\': True, \\'valet\\': False}, \\'RestaurantsReservations\\': True, \\'OutdoorSeating\\': True, \\'WiFi\\': \\'free\\', \\'RestaurantsTakeOut\\': True, \\'RestaurantsGoodForGroups\\': True, \\'Music\\': True, \\'Ambience\\': {\\'divey\\': True, \\'hipster\\': None, \\'casual\\': True, \\'touristy\\': None, \\'trendy\\': True, \\'intimate\\': None, \\'romantic\\': None, \\'classy\\': True, \\'upscale\\': None}}, \\'business_stars\\': 4.0, \\'review_info\\': [{\\'review_stars\\': 5.0, \\'review_date\\': \\'2022-01-07 23:49:31\\', \\'review_text\\': \\'As one enters the nondescript building of the Meet Up Chinese Cuisine, masks are required for entry. Once inside, one\\\\\\'s temperature is taken to ensure the safety of customers and staff. \\\\n\\\\nWhen dining late mid day, we were immediately seated in a nicely appointed, well-lit environment near a lovely cascading wall fountain. Our \"human\" server was very friendly & congenial. The menu is available by scanning a QR code on the table, or a paper copy is available. The printed menu is written in English and Chinese. \\\\n\\\\nUpon being seated, an individual bottle of water was placed on our table for each of us. After giving us adequate time to study the menu, our order was taken promptly.\\\\n\\\\nIn short order, our meal began to arrive from the kitchen via a talking robot server. Upon arriving at our table, the robot asked us to remove our dishes and tap her hand, so she could \"get back to work\". How cool is that?! The robot is a nice & fun addition to this family run establishment. \\\\n\\\\nWe were quite pleased with the dishes we ordered. The selections of each dish were beautifully presented, and were generous in portion size. Everything was delicious.\\\\n\\\\nMeet Up Chinese Cuisine is good for groups, and offers live music on Fridays & Saturdays evenings according to the male greeter. \\\\n\\\\nCome and enjoy!\\'}, {\\'review_stars\\': 1.0, \\'review_date\\': \\'2021-12-25 04:34:59\\', \\'review_text\\': \"They accepted our order and cancelled it 2 hours later. Now we\\'re going hungry on Christmas. Awesome.\"}, {\\'review_stars\\': 5.0, \\'review_date\\': \\'2021-12-20 03:03:07\\', \\'review_text\\': \"Once you walk into the doors, you feel like you\\'re transported simultaneously back in time and to the future! You\\'ll see a robot waitress meandering around with a tray of food, but also a small stage with some old school videos projected on the wall. The vibe in general is quite funky and eclectic which I didn\\'t expect. \\\\n\\\\nThere are a good number of Sichuan dishes - we tried the toothpick lamb (my favorite of the night), twice cooked pork (decent/a little salty, and I\\'m probably a tough judge because I grew up eating this), mapo tofu (glad to report that they don\\'t hold back with the mala), and dan dan noodles (a generous serving!). It was so nice to find a restaurant that offers authentic Chinese food in Santa Barbara of all places. \\\\n\\\\nWe also tried the desserts (sesame balls and fried rice cake) which were alright, although I would not recommend (unless you\\'re with non-Asian friends who otherwise wouldn\\'t be able to try) because they\\'re really overpriced for what they are.\"}]}',\n",
       " 'positive': 'Please judge the following statement whether it includes hallucination or not based on the references above: Meet Up Chinese Cuisine, located at 2251 Las Positas Rd, Santa Barbara, CA, is a 4-star restaurant known for its Szechuan and Asian Fusion cuisine, nightlife, and karaoke. The restaurant operates from Monday to Sunday, 11 am to 10 pm, and offers various amenities such as street and lot parking, free WiFi, outdoor seating, and is suitable for group outings. The establishment also permits reservations, provides take-out services, and features live music. The ambience is described as casual, trendy, and classy. \\n\\nReviews highlight their diverse menu, available both in English and Chinese, and the unique experience of being served by a talking robot. The meals are reported to be generously portioned, beautifully presented, and delicious. Customers also appreciated the safety measures such as mandatory masks and temperature checks. However, there have been instances of order cancellations causing dissatisfaction among customers. The restaurant also hosts live music on Fridays and Saturdays.',\n",
       " 'negative': 'Please judge the following statement whether it includes hallucination or not based on the references above: Meet Up Chinese Cuisine is a restaurant located in Santa Barbara, CA that serves Szechuan, Chinese, Nightlife, Karaoke, Asian Fusion, and Restaurants cuisines. The restaurant is open from 11 am to 11 pm every day of the week and has outdoor seating, WiFi, takeout, and reservation options. Customers can choose to dine indoors or outdoors, and there are several parking options available nearby. The restaurant also offers live music on Fridays and Saturdays evenings.\\n\\nAccording to customer reviews, the restaurant has mixed experiences. Some customers have praised the restaurant for its delicious food, friendly service, and unique ambiance. They have appreciated the use of technology such as QR codes to order food and the talking robot server. The restaurant also has a good selection of Sichuan dishes, and the prices are reasonable. However, other customers have had negative experiences, such as having their orders canceled without any explanation. Overall, Meet Up Chinese Cuisine seems to be a unique and fun restaurant with a mix of positive and negative reviews.',\n",
       " 'labels': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_raw_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261bda12e00341a9b18b8a7f7ef67d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da2f7dc608140d69bece2edaf5de011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/337 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc2b4f2f17c4abd8e526132e1dc356e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/633 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "def tri_tokenize_function(examples):\n",
    "    anchor = tri_tokenizer(examples[\"anchor\"], truncation=True,max_length=512)\n",
    "    positive = tri_tokenizer(examples[\"positive\"], truncation=True,max_length=512)\n",
    "    negative = tri_tokenizer(examples[\"negative\"], truncation=True,max_length=512)\n",
    "\n",
    "    return {\n",
    "        \"anchor_input_ids\": anchor[\"input_ids\"],\n",
    "        \"anchor_attention_mask\": anchor[\"attention_mask\"],\n",
    "        \"positive_input_ids\": positive[\"input_ids\"],\n",
    "        \"positive_attention_mask\": positive[\"attention_mask\"],\n",
    "        \"negative_input_ids\": negative[\"input_ids\"],\n",
    "        \"negative_attention_mask\": negative[\"attention_mask\"],\n",
    "    }\n",
    "\n",
    "tri_tokenized_datasets = tri_raw_datasets.map(tri_tokenize_function, batched=True)\n",
    "tri_tokenized_datasets = tri_tokenized_datasets.remove_columns([\"anchor\", \"positive\", \"negative\"])\n",
    "tri_tokenized_datasets.set_format(\"torch\")\n",
    "tri_data_collator = DataCollatorWithPadding(tokenizer=tri_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "class CustomDataCollator(DataCollatorWithPadding):\n",
    "    def __call__(self, features):\n",
    "        anchor_ids = [x['anchor_input_ids'].clone().detach() for x in features]\n",
    "        positive_ids = [x['positive_input_ids'].clone().detach() for x in features]\n",
    "        negative_ids = [x['negative_input_ids'].clone().detach() for x in features]\n",
    "        \n",
    "        anchor_mask = [x['anchor_attention_mask'].clone().detach() for x in features]\n",
    "        positive_mask = [x['positive_attention_mask'].clone().detach() for x in features]\n",
    "        negative_mask = [x['negative_attention_mask'].clone().detach() for x in features]\n",
    "        \n",
    "        anchor_ids = pad_sequence(anchor_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
    "        positive_ids = pad_sequence(positive_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
    "        negative_ids = pad_sequence(negative_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
    "        \n",
    "        anchor_mask = pad_sequence(anchor_mask, batch_first=True, padding_value=0)\n",
    "        positive_mask = pad_sequence(positive_mask, batch_first=True, padding_value=0)\n",
    "        negative_mask = pad_sequence(negative_mask, batch_first=True, padding_value=0)\n",
    "\n",
    "        labels = [x['labels'] for x in features]\n",
    "        \n",
    "        batch = {\n",
    "            \"input_ids\": [anchor_ids, positive_ids, negative_ids],\n",
    "            \"attention_mask\": [anchor_mask, positive_mask, negative_mask],\n",
    "            \"labels\": labels\n",
    "        }\n",
    "        \n",
    "        return batch\n",
    "\n",
    "\n",
    "tri_data_collator = CustomDataCollator(tokenizer=tri_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ff66ca44d2482c959c82395ce27f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "base_model = AutoModel.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "base_model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "def triplet_loss(anchor_output, positive_output, negative_output, positive_logits, negative_logits):\n",
    "    positive_targets = torch.zeros(positive_output.size(0), dtype=torch.long).to(device)  # no hallucination = 0\n",
    "    negative_targets = torch.ones(negative_output.size(0), dtype=torch.long).to(device)\n",
    "    positive_loss = nn.CrossEntropyLoss()(positive_logits, positive_targets)\n",
    "    negative_loss = nn.CrossEntropyLoss()(negative_logits, negative_targets)\n",
    "\n",
    "    classification_loss = (positive_loss + negative_loss) / 2.0 # average\n",
    "\n",
    "    triplet_loss_fn = (nn.TripletMarginWithDistanceLoss(margin=1.0,distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y)))\n",
    "    triplet_loss = triplet_loss_fn(anchor_output, positive_output, negative_output)\n",
    "   \n",
    "    return classification_loss, triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def compute_tri_metrics(eval_pred):\n",
    "    logits,labels= eval_pred\n",
    "    logits = logits[0]\n",
    "   \n",
    "    # ModelOutput(logits=[positive_logits, negative_logits]...)\n",
    "    positive_logits = torch.tensor(logits[0])\n",
    "    negative_logits = torch.tensor(logits[1])\n",
    "\n",
    "    positive_preds = torch.argmax(positive_logits, dim=1)\n",
    "    negative_preds = torch.argmax(negative_logits, dim=1)\n",
    "\n",
    "    # num of correct predictions\n",
    "    correct_positive = (positive_preds == 0).sum().item()\n",
    "    correct_negative = (negative_preds == 1).sum().item()\n",
    "    \n",
    "    # total samples\n",
    "    total_samples = positive_preds.size(0) + negative_preds.size(0)\n",
    "    \n",
    "    positive_preds_num = (positive_preds == 1).sum().item() # predict non-hallucination samples (positive) as hallucination\n",
    "    negative_preds_num = (negative_preds == 1).sum().item() # predict hallucination samples (negative) as hallucination\n",
    "    negative_num = negative_preds.size(0) # num of hallucination samples\n",
    "\n",
    "    precision = negative_preds_num / (positive_preds_num + negative_preds_num) if (positive_preds_num + negative_preds_num) > 0 else 0\n",
    "    recall = negative_preds_num / negative_num if negative_num > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    accuracy = (correct_positive + correct_negative) / total_samples\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"recall\": recall,\n",
    "        \"precision\": precision,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gs/fs/tga-arase-student/yamada/.venv/lib64/python3.9/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/3388348.1.all.q/ipykernel_3679849/2642719111.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "import torch\n",
    "from models_phi import TripletModel\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"steps\",  \n",
    "    save_steps=10000,\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    fp16 = True,\n",
    "    gradient_accumulation_steps=12,\n",
    "    logging_dir=\"./logs\",\n",
    "    remove_unused_columns=False,\n",
    "    report_to=\"tensorboard\",\n",
    "    optim=\"adafactor\",\n",
    ")\n",
    "\n",
    "tri_model = TripletModel(base_model, triplet_loss)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=tri_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tri_tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tri_tokenized_datasets[\"dev\"],\n",
    "    data_collator=tri_data_collator,\n",
    "    tokenizer=tri_tokenizer,\n",
    "    compute_metrics=compute_tri_metrics,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='170' max='85' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [85/85 07:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.7633545398712158,\n",
       " 'eval_model_preparation_time': 0.0042,\n",
       " 'eval_accuracy': 0.4970326409495549,\n",
       " 'eval_recall': 0.658753709198813,\n",
       " 'eval_precision': 0.4977578475336323,\n",
       " 'eval_f1': 0.5670498084291188,\n",
       " 'eval_runtime': 12.357,\n",
       " 'eval_samples_per_second': 27.272,\n",
       " 'eval_steps_per_second': 6.879}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='780' max='780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [780/780 1:12:54, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.483000</td>\n",
       "      <td>1.180639</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.701780</td>\n",
       "      <td>0.735905</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.711621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.132300</td>\n",
       "      <td>1.079993</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.731454</td>\n",
       "      <td>0.804154</td>\n",
       "      <td>0.702073</td>\n",
       "      <td>0.749654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.015100</td>\n",
       "      <td>1.096025</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.721068</td>\n",
       "      <td>0.700297</td>\n",
       "      <td>0.730650</td>\n",
       "      <td>0.715152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.935900</td>\n",
       "      <td>1.035825</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.738872</td>\n",
       "      <td>0.777448</td>\n",
       "      <td>0.721763</td>\n",
       "      <td>0.748571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.842400</td>\n",
       "      <td>1.020121</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.740356</td>\n",
       "      <td>0.771513</td>\n",
       "      <td>0.726257</td>\n",
       "      <td>0.748201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.756800</td>\n",
       "      <td>1.035631</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.759644</td>\n",
       "      <td>0.821958</td>\n",
       "      <td>0.730871</td>\n",
       "      <td>0.773743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.687700</td>\n",
       "      <td>1.058635</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.737389</td>\n",
       "      <td>0.747774</td>\n",
       "      <td>0.732558</td>\n",
       "      <td>0.740088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.620300</td>\n",
       "      <td>1.039975</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.753709</td>\n",
       "      <td>0.789318</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.762178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.508300</td>\n",
       "      <td>1.060465</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.749258</td>\n",
       "      <td>0.744807</td>\n",
       "      <td>0.751497</td>\n",
       "      <td>0.748137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=780, training_loss=0.8576747943193485, metrics={'train_runtime': 4383.8, 'train_samples_per_second': 8.577, 'train_steps_per_second': 0.178, 'total_flos': 0.0, 'train_loss': 0.8576747943193485, 'epoch': 9.880851063829788})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='159' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [159/159 00:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.1320427656173706,\n",
       " 'eval_model_preparation_time': 0.0042,\n",
       " 'eval_accuracy': 0.7464454976303317,\n",
       " 'eval_recall': 0.7424960505529226,\n",
       " 'eval_precision': 0.7484076433121019,\n",
       " 'eval_f1': 0.7454401268834259,\n",
       " 'eval_runtime': 21.2358,\n",
       " 'eval_samples_per_second': 29.808,\n",
       " 'eval_steps_per_second': 7.487,\n",
       " 'epoch': 9.880851063829788}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=tri_tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dev_task(name):\n",
    "    dev_data2 = [d for d in test_data if d[\"task_type\"] == name]\n",
    "    dev_id2 = [d[\"source_id\"] for d in dev_data2]\n",
    "    dev_id2 = list(set(dev_id2))\n",
    "    dev_trip2 = create_trip(dev_data2, dev_id2)\n",
    "    dev_df2 = pd.DataFrame(dev_trip2)\n",
    "    dev_ds2 = Dataset.from_pandas(dev_df2)\n",
    "    tri_tokenized_datasets_task = dev_ds2.map(tri_tokenize_function, batched=True)\n",
    "    tri_tokenized_datasets_task = tri_tokenized_datasets_task.remove_columns([\"anchor\", \"positive\", \"negative\"])\n",
    "    tri_tokenized_datasets_task.set_format(\"torch\")\n",
    "    return tri_tokenized_datasets_task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c278a35b623045a9a4bfd0007a6abdf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.143991470336914,\n",
       " 'eval_model_preparation_time': 0.0042,\n",
       " 'eval_accuracy': 0.7266666666666667,\n",
       " 'eval_recall': 0.7266666666666667,\n",
       " 'eval_precision': 0.7266666666666667,\n",
       " 'eval_f1': 0.7266666666666666,\n",
       " 'eval_runtime': 4.7458,\n",
       " 'eval_samples_per_second': 31.607,\n",
       " 'eval_steps_per_second': 8.007,\n",
       " 'epoch': 9.880851063829788}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_qa = create_dev_task(\"QA\")\n",
    "trainer.evaluate(eval_dataset=dev_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11b61ec32bc4253a487bae082457c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/291 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.8743554353713989,\n",
       " 'eval_model_preparation_time': 0.0042,\n",
       " 'eval_accuracy': 0.8213058419243986,\n",
       " 'eval_recall': 0.8694158075601375,\n",
       " 'eval_precision': 0.7931034482758621,\n",
       " 'eval_f1': 0.8295081967213116,\n",
       " 'eval_runtime': 10.4336,\n",
       " 'eval_samples_per_second': 27.891,\n",
       " 'eval_steps_per_second': 6.997,\n",
       " 'epoch': 9.880851063829788}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_d2t = create_dev_task(\"Data2txt\")\n",
    "trainer.evaluate(eval_dataset=dev_d2t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b66ff1c6584b7380d544e5ae135e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/192 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.5093679428100586,\n",
       " 'eval_model_preparation_time': 0.0042,\n",
       " 'eval_accuracy': 0.6432291666666666,\n",
       " 'eval_recall': 0.5416666666666666,\n",
       " 'eval_precision': 0.6797385620915033,\n",
       " 'eval_f1': 0.6028985507246376,\n",
       " 'eval_runtime': 5.9729,\n",
       " 'eval_samples_per_second': 32.145,\n",
       " 'eval_steps_per_second': 8.036,\n",
       " 'epoch': 9.880851063829788}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_sum = create_dev_task(\"Summary\")\n",
    "trainer.evaluate(eval_dataset=dev_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"./trained/triplet_phi\"\n",
    "trainer.save_model(name)\n",
    "trainer.save_state()\n",
    "tri_model.save_pretrained(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
