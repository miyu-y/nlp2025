{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"dataset/rag_truth_train.json\", \"r\") as f:\n",
    "    train_data = json.load(f)\n",
    "with open(\"dataset/rag_truth_dev.json\", \"r\") as f:\n",
    "    dev_data = json.load(f)\n",
    "with open(\"dataset/rag_truth_test.json\", \"r\") as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prefix(data):\n",
    "    for d in data:\n",
    "        d[\"text\"] = \"Please judge the following statement whether it includes hallucination or not based on the references above: \" + d[\"text\"]\n",
    "    return data\n",
    "\n",
    "train_data = add_prefix(train_data)\n",
    "dev_data = add_prefix(dev_data)\n",
    "test_data = add_prefix(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_type: QA, Data2txt, Summary\n",
    "task_name = \"Data2txt\"\n",
    "train_data = [d for d in train_data if d[\"task_type\"] == task_name]\n",
    "dev_data = [d for d in dev_data if d[\"task_type\"] == task_name]\n",
    "test_data = [d for d in test_data if d[\"task_type\"] == task_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def create_trip(data, id_list):\n",
    "    trip = []\n",
    "    for id in id_list:\n",
    "        num = 0\n",
    "        no_hal = []\n",
    "        has_hal = []\n",
    "        for d in data:\n",
    "            if num == 6:\n",
    "                num = 0\n",
    "                if no_hal == [] or has_hal == []:\n",
    "                    break\n",
    "                # shuffle\n",
    "                random.seed(id) # change seed\n",
    "                no_hal = random.sample(no_hal, len(no_hal))\n",
    "                has_hal = random.sample(has_hal, len(has_hal))\n",
    "                \n",
    "                if len(no_hal)==1 or len(no_hal)==5:\n",
    "                    trip.append({\"anchor\":ref,\"positive\": no_hal[0], \"negative\": has_hal[0], \"labels\": 0}) # labels are dummy \n",
    "                elif len(no_hal)==2 or len(no_hal)==4:\n",
    "                    trip.append({\"anchor\":ref,\"positive\": no_hal[0], \"negative\": has_hal[0], \"labels\": 0})\n",
    "                    trip.append({\"anchor\":ref,\"positive\": no_hal[1], \"negative\": has_hal[1], \"labels\": 0})\n",
    "                elif len(no_hal)==3:\n",
    "                    trip.append({\"anchor\":ref,\"positive\": no_hal[0], \"negative\": has_hal[0], \"labels\": 0})\n",
    "                    trip.append({\"anchor\":ref,\"positive\": no_hal[1], \"negative\": has_hal[1], \"labels\": 0})\n",
    "                    trip.append({\"anchor\":ref,\"positive\": no_hal[2], \"negative\": has_hal[2], \"labels\": 0})\n",
    "                no_hal = []\n",
    "                has_hal = []\n",
    "                break\n",
    "            elif d[\"source_id\"] == id:\n",
    "                num +=1\n",
    "                ref = d[\"ref\"]\n",
    "                if d[\"labels\"] == 0:\n",
    "                    no_hal.append(d[\"text\"])\n",
    "                else: #hallucination\n",
    "                    has_hal.append(d[\"text\"])\n",
    "        if num == 6:\n",
    "            if len(no_hal)==1 or len(no_hal)==5:\n",
    "                trip.append({\"anchor\":ref,\"positive\": no_hal[0], \"negative\": has_hal[0], \"labels\": 0})\n",
    "            elif len(no_hal)==2 or len(no_hal)==4:\n",
    "                trip.append({\"anchor\":ref,\"positive\": no_hal[0], \"negative\": has_hal[0], \"labels\": 0})\n",
    "                trip.append({\"anchor\":ref,\"positive\": no_hal[1], \"negative\": has_hal[1], \"labels\": 0})\n",
    "            elif len(no_hal)==3:\n",
    "                trip.append({\"anchor\":ref,\"positive\": no_hal[0], \"negative\": has_hal[0], \"labels\": 0})\n",
    "                trip.append({\"anchor\":ref,\"positive\": no_hal[1], \"negative\": has_hal[1], \"labels\": 0})\n",
    "                trip.append({\"anchor\":ref,\"positive\": no_hal[2], \"negative\": has_hal[2], \"labels\": 0})\n",
    "    return trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2305 210 450\n"
     ]
    }
   ],
   "source": [
    "train_id = [d[\"source_id\"] for d in train_data]\n",
    "train_id = list(set(train_id))\n",
    "dev_id = [d[\"source_id\"] for d in dev_data]\n",
    "dev_id = list(set(dev_id))\n",
    "test_id = [d[\"source_id\"] for d in test_data]\n",
    "test_id = list(set(test_id))\n",
    "print(len(train_id), len(dev_id), len(test_id))\n",
    "train_trip = create_trip(train_data, train_id)\n",
    "dev_trip = create_trip(dev_data, dev_id)\n",
    "test_trip = create_trip(test_data, test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3760, 337, 633)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_trip), len(dev_trip), len(test_trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gs/fs/tga-arase-student/yamada/.venv/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['anchor', 'positive', 'negative', 'labels'],\n",
       "        num_rows: 3760\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['anchor', 'positive', 'negative', 'labels'],\n",
       "        num_rows: 337\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['anchor', 'positive', 'negative', 'labels'],\n",
       "        num_rows: 633\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.DataFrame(train_trip)\n",
    "dev_df = pd.DataFrame(dev_trip)\n",
    "test_df = pd.DataFrame(test_trip)\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "dev_ds = Dataset.from_pandas(dev_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "\n",
    "tri_raw_datasets = DatasetDict({\"train\": train_ds, \"dev\": dev_ds, \"test\": test_ds})\n",
    "tri_raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tri_tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/RoBERTa-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anchor': 'Dongguan, China (CNN)For a decade, the New South China Mall -- the biggest shopping mall in the world -- has been an embarrassment for its owners and China. Opened to the public in 2005 in Dongguan in the south of the country, the goal was to attract 100,000 visitors a day with an array of entertainment, shops and eateries. Outside the mall, a giant Egyptian sphinx and a replica of the Arc de Triomphe were erected alongside fountains and canals complete with Venetian gondolas. It even boasted an indoor roller coaster. But despite the grand plans neither stores nor shoppers came. Soon, it was classified by industry analysts as a \"dead mall\" and it became an unflattering symbol of China\\'s runaway speculation on real estate projects. The mall spans five million square feet of shopping area, making it the largest in the world in terms of leasable space -- more than twice the size of Mall of America, the biggest shopping center in the United States. When I visited two years ago, the mall was deserted. Most units were empty. Paint was coming off the walls and store signs and advertisements had faded. The air had a dry smell of dust and garbage was piled everywhere. The occupancy rate was less than 10%. It was a walk through a ghost mall. However, a visit in late March revealed a different picture. The mall was buzzing with activity. Large parts of the previously abandoned buildings are now full of shops, restaurants and entertainment venues. Visitors could be seen browsing for luxury sunglasses and designer jeans, dining at the Korean, Italian or Chinese restaurants or enjoying the new entertainment facilities. Screams and laughter can be heard from merry-go-rounds. \"It\\'s been a big change. It\\'s a clear modernization,\" said David Carr, an English teacher from the United States who is living in Dongguan with his wife Danae, also a teacher. \"We come here at least once a month now.\" Despite the signs of life, much of the mall is still vacant. But most of the unoccupied units, along with halls and walkways are under renovation. Even on a Saturday, it\\'s full of construction workers and the constant sound of jack-hammering and sawing. Ms Shu, head of New South China Mall\\'s marketing unit, told CNN that there are plans for a re-launch ceremony this spring, when all construction work will be completed and most shop and restaurant areas are leased to tenants. \"All construction that is currently going on at the mall is preparation for the opening in May,\" she said, declining to give her full name. \"We expect that from May, we will have almost full occupancy rate and no empty shops.\" She said she couldn\\'t offer any more details as she was not authorized to speak with media. Ms Ye, head of investments, confirmed that \"business is really great,\" but would not comment further. Dutch retail chain Spar, which has expanded its supermarket to two floors, explained on its website that it had re-launched last year during the mall\\'s \"upgrading and retrofitting program.\" There are also plenty of recruitment ads posted at the entrance of the mall. When I spoke to her, Huang Haiyan, a young Chinese woman, was just two days away from opening a little café called \"Miss & H\" in one of the passage ways being renovated. Sitting on the sidewalk outside the café, she and her partners were busy washing up cups, classes and plates ahead of the big day. \"I\\'m so excited!\" she said, showing the kind of enthusiasm that had been non-existent when I last visited the mall two years ago. \"You must come, my coffee is the best in China!\" The area around the previously run-down Arc de Triomphe is now a tranquil roofed boulevard with small coffee shops where youngsters play cards and mothers sip lattes. In January, a globe shaped IMAX-style cinema was launched at the outdoor square. One of the more eye-catching new sources of entertainment is a role-playing amusement center for children called Myrules World. Today, it no longer feels like a walk through a ghost mall. It\\'s hard to believe how rapid the change has been. Economist Brian Jackson says the shift in focus towards restaurants and businesses that target China\\'s middle, rather than, upper class, is a smart move on behalf of the developers. \"Many large malls (and residential construction) in China.... are all hoping to target one demographic -- the upper class,\" he said. \"What is needed to succeed is retail space that caters to (the much larger) bulk of middle-class Chinese.\" And, he says, other developments that were once labeled \"ghost cities\" have gone on to thrive. \"One to three years is a blink of an eye in terms of city developments, so many of these cities still have time to fill and become functional,\"Jackson said. Despite its retrofitting program, the problems that have dogged the mall since its start will not disappear instantly. Most of Dongguan\\'s almost 10 million inhabitants are migrant workers struggling to make ends meet. The town is also facing difficulties as manufacturing moves elsewhere in China or to Southeast Asia where wages are lower. China is also haunted by serious problems in its real-estate market, with over investment and large vacancy rates. In March, prices of new homes fell for the twelfth consecutive month. What\\'s more, the mall\\'s latest re-launch is not its first. In 2007, the mall changed name from \"South China Mall\" to \"New South China Mall, Living City\" and a revitalization plan was drawn up by current owners the Founders Group, a conglomerate set up by Peking University, and its subsidiary PKU Founder. But the revamp failed and the mall remained empty. Now, the owners are hoping for third time lucky. PICTURES: Inside a Chinese ghost city.\\n',\n",
       " 'positive': 'Please judge the following statement whether it includes hallucination or not based on the references above: The New South China Mall, the world\\'s largest shopping centre, which was previously dubbed a \"dead mall\" due to its lack of tenants and visitors, is reportedly now buzzing with activity. The mall, which spans five million square feet, has been revitalised with new shops, restaurants and entertainment venues. A spokesperson for the mall said that they expect the mall to have \"almost full occupancy rate and no empty shops\" from May, following the completion of construction work and a re-launch. Peking University\\'s Founders Group and its subsidiary PKU Founder, the current owners of the mall, are hoping that the latest efforts to revitalise the mall will prove successful following the failure of a previous attempt in 2007.',\n",
       " 'negative': 'Please judge the following statement whether it includes hallucination or not based on the references above: The New South China Mall, once dubbed the \"world\\'s biggest ghost mall,\" is undergoing a major transformation after a decade of struggles. The mall, located in Dongguan, China, was opened in 2005 with grand ambitions to attract 100,000 visitors a day. However, it quickly became a symbol of China\\'s runaway speculation on real estate projects due to its lack of success. The mall spans five million square feet of shopping area, making it the largest in the world, yet it was mostly empty with a less than 10% occupancy rate.\\n\\nRecently, there has been a surge of activity within the mall, with large parts of the previously abandoned buildings now filled with shops, restaurants, and entertainment venues. The mall is undergoing a $1 billion renovation, which is expected to be completed by May. According to the mall\\'s marketing head, Ms. Shu, the aim is to have almost full occupancy rate and no empty shops by then. The owners are hopeful that the revamp will finally turn the mall into a success story.\\n\\nDespite the signs of life, much of the mall is still vacant, and construction work is ongoing. However, the area around the Arc de Triomphe has transformed into a tranquil roofed boulevard with small coffee shops and a new IMAX-style cinema. A new source of entertainment, Myrules World, a role-playing amusement center for children, has also been added.\\n\\nEconomist Brian Jackson believes that the shift in focus towards restaurants and businesses that cater to China\\'s middle class is a smart move, as the bulk of the population is made up of this demographic. He notes that many large malls and residential construction projects in China are targeting the upper class, but this approach may not be sustainable.\\n\\nThe New South China Mall\\'s transformation is a promising sign, but the challenges faced by the mall and Dongguan as a whole are significant. The town is home to nearly 10 million migrant workers struggling to make ends meet, and the manufacturing sector is facing challenges as it moves elsewhere in China or to Southeast Asia. Additionally, the real estate market in',\n",
       " 'labels': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_raw_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/3760 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3760/3760 [00:02<00:00, 1733.64 examples/s]\n",
      "Map: 100%|██████████| 337/337 [00:00<00:00, 1829.40 examples/s]\n",
      "Map: 100%|██████████| 633/633 [00:00<00:00, 1845.27 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "def tri_tokenize_function(examples):\n",
    "    anchor = tri_tokenizer(examples[\"anchor\"], truncation=True,max_length=512,padding=\"max_length\")\n",
    "    positive = tri_tokenizer(examples[\"positive\"], truncation=True,max_length=512,padding=\"max_length\")\n",
    "    negative = tri_tokenizer(examples[\"negative\"], truncation=True,max_length=512,padding=\"max_length\")\n",
    "\n",
    "    return {\n",
    "        \"anchor_input_ids\": anchor[\"input_ids\"],\n",
    "        \"anchor_attention_mask\": anchor[\"attention_mask\"],\n",
    "        \"positive_input_ids\": positive[\"input_ids\"],\n",
    "        \"positive_attention_mask\": positive[\"attention_mask\"],\n",
    "        \"negative_input_ids\": negative[\"input_ids\"],\n",
    "        \"negative_attention_mask\": negative[\"attention_mask\"],\n",
    "    }\n",
    "\n",
    "tri_tokenized_datasets = tri_raw_datasets.map(tri_tokenize_function, batched=True)\n",
    "tri_tokenized_datasets = tri_tokenized_datasets.remove_columns([\"anchor\", \"positive\", \"negative\"])\n",
    "tri_data_collator = DataCollatorWithPadding(tokenizer=tri_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "class CustomDataCollator(DataCollatorWithPadding):\n",
    "    def __call__(self, features):\n",
    "        anchor_ids = [torch.tensor(x['anchor_input_ids']) for x in features]\n",
    "        positive_ids = [torch.tensor(x['positive_input_ids']) for x in features]\n",
    "        negative_ids = [torch.tensor(x['negative_input_ids']) for x in features]\n",
    "        \n",
    "        anchor_mask = [torch.tensor(x['anchor_attention_mask']) for x in features]\n",
    "        positive_mask = [torch.tensor(x['positive_attention_mask']) for x in features]\n",
    "        negative_mask = [torch.tensor(x['negative_attention_mask']) for x in features]\n",
    "        \n",
    "        anchor_ids = pad_sequence(anchor_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
    "        positive_ids = pad_sequence(positive_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
    "        negative_ids = pad_sequence(negative_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
    "        \n",
    "        anchor_mask = pad_sequence(anchor_mask, batch_first=True, padding_value=0)\n",
    "        positive_mask = pad_sequence(positive_mask, batch_first=True, padding_value=0)\n",
    "        negative_mask = pad_sequence(negative_mask, batch_first=True, padding_value=0)\n",
    "        \n",
    "        labels = [torch.tensor(x['labels']) for x in features]\n",
    "        \n",
    "        batch = {\n",
    "            \"input_ids\": [anchor_ids, positive_ids, negative_ids],\n",
    "            \"attention_mask\": [anchor_mask, positive_mask, negative_mask],\n",
    "            \"labels\": labels\n",
    "        }\n",
    "        \n",
    "        return batch\n",
    "\n",
    "\n",
    "tri_data_collator = CustomDataCollator(tokenizer=tri_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "base_model = AutoModel.from_pretrained(\"FacebookAI/RoBERTa-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "base_model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "def triplet_loss(anchor_output, positive_output, negative_output, positive_logits, negative_logits):\n",
    "    positive_targets = torch.zeros(positive_output.size(0), dtype=torch.long).to(device)  # no hallucination = 0\n",
    "    negative_targets = torch.ones(negative_output.size(0), dtype=torch.long).to(device)\n",
    "    positive_loss = nn.CrossEntropyLoss()(positive_logits, positive_targets)\n",
    "    negative_loss = nn.CrossEntropyLoss()(negative_logits, negative_targets)\n",
    "\n",
    "    classification_loss = (positive_loss + negative_loss) / 2.0 # average\n",
    "\n",
    "    triplet_loss_fn = (nn.TripletMarginWithDistanceLoss(margin=1.0,distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y)))\n",
    "    triplet_loss = triplet_loss_fn(anchor_output, positive_output, negative_output)\n",
    "   \n",
    "    return classification_loss, triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def compute_tri_metrics(eval_pred):\n",
    "    logits,labels= eval_pred\n",
    "    logits = logits[0]\n",
    "   \n",
    "    # ModelOutput(logits=[positive_logits, negative_logits]...)\n",
    "    positive_logits = torch.tensor(logits[0])\n",
    "    negative_logits = torch.tensor(logits[1])\n",
    "\n",
    "    positive_preds = torch.argmax(positive_logits, dim=1)\n",
    "    negative_preds = torch.argmax(negative_logits, dim=1)\n",
    "\n",
    "    # num of correct predictions\n",
    "    correct_positive = (positive_preds == 0).sum().item()\n",
    "    correct_negative = (negative_preds == 1).sum().item()\n",
    "    \n",
    "    # total samples\n",
    "    total_samples = positive_preds.size(0) + negative_preds.size(0)\n",
    "    \n",
    "    positive_preds_num = (positive_preds == 1).sum().item() # predict non-hallucination samples (positive) as hallucination\n",
    "    negative_preds_num = (negative_preds == 1).sum().item() # predict hallucination samples (negative) as hallucination\n",
    "    negative_num = negative_preds.size(0) # num of hallucination samples\n",
    "\n",
    "    precision = negative_preds_num / (positive_preds_num + negative_preds_num) if (positive_preds_num + negative_preds_num) > 0 else 0\n",
    "    recall = negative_preds_num / negative_num if negative_num > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    accuracy = (correct_positive + correct_negative) / total_samples\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"recall\": recall,\n",
    "        \"precision\": precision,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "import torch\n",
    "from models_rob import TripletModel\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"steps\",  \n",
    "    save_steps=10000,\n",
    "    learning_rate=5e-6,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    fp16 = True,\n",
    "    gradient_accumulation_steps=3,\n",
    "    logging_dir=\"./logs\",\n",
    "    remove_unused_columns=False,\n",
    "    report_to=\"tensorboard\",\n",
    ")\n",
    "\n",
    "tri_model = TripletModel(base_model, triplet_loss)\n",
    "trainer = Trainer(\n",
    "    model=tri_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tri_tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tri_tokenized_datasets[\"dev\"],\n",
    "    data_collator=tri_data_collator,\n",
    "    tokenizer=tri_tokenizer,\n",
    "    compute_metrics=compute_tri_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='170' max='85' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [85/85 01:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.7031710147857666,\n",
       " 'eval_model_preparation_time': 0.0022,\n",
       " 'eval_accuracy': 0.5,\n",
       " 'eval_recall': 0.0,\n",
       " 'eval_precision': 0,\n",
       " 'eval_f1': 0,\n",
       " 'eval_runtime': 2.2992,\n",
       " 'eval_samples_per_second': 146.573,\n",
       " 'eval_steps_per_second': 36.969}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3130' max='3130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3130/3130 11:12, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.487700</td>\n",
       "      <td>1.170633</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.701780</td>\n",
       "      <td>0.857567</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.741977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.116900</td>\n",
       "      <td>1.196219</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.692878</td>\n",
       "      <td>0.937685</td>\n",
       "      <td>0.629482</td>\n",
       "      <td>0.753278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.025000</td>\n",
       "      <td>1.115803</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.709199</td>\n",
       "      <td>0.928783</td>\n",
       "      <td>0.645361</td>\n",
       "      <td>0.761557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.965600</td>\n",
       "      <td>1.049453</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.729970</td>\n",
       "      <td>0.916914</td>\n",
       "      <td>0.667387</td>\n",
       "      <td>0.772500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.909600</td>\n",
       "      <td>1.140414</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.698813</td>\n",
       "      <td>0.922849</td>\n",
       "      <td>0.637295</td>\n",
       "      <td>0.753939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.851900</td>\n",
       "      <td>1.099777</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.715134</td>\n",
       "      <td>0.925816</td>\n",
       "      <td>0.651357</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.825800</td>\n",
       "      <td>1.133316</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.710682</td>\n",
       "      <td>0.928783</td>\n",
       "      <td>0.646694</td>\n",
       "      <td>0.762485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.792200</td>\n",
       "      <td>1.159150</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.697329</td>\n",
       "      <td>0.931751</td>\n",
       "      <td>0.634343</td>\n",
       "      <td>0.754808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.735400</td>\n",
       "      <td>1.170486</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.703264</td>\n",
       "      <td>0.928783</td>\n",
       "      <td>0.640082</td>\n",
       "      <td>0.757869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3130, training_loss=0.947699827736559, metrics={'train_runtime': 673.2048, 'train_samples_per_second': 55.852, 'train_steps_per_second': 4.649, 'total_flos': 0.0, 'train_loss': 0.947699827736559, 'epoch': 9.970212765957447})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='159' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  6/159 00:00 < 00:03, 44.05 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.243459939956665,\n",
       " 'eval_model_preparation_time': 0.0022,\n",
       " 'eval_accuracy': 0.6951026856240127,\n",
       " 'eval_recall': 0.9462875197472354,\n",
       " 'eval_precision': 0.629863301787592,\n",
       " 'eval_f1': 0.7563131313131312,\n",
       " 'eval_runtime': 3.4686,\n",
       " 'eval_samples_per_second': 182.494,\n",
       " 'eval_steps_per_second': 45.84,\n",
       " 'epoch': 9.970212765957447}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=tri_tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dev_task(name):\n",
    "    dev_data2 = [d for d in test_data if d[\"task_type\"] == name]\n",
    "    dev_id2 = [d[\"source_id\"] for d in dev_data2]\n",
    "    dev_id2 = list(set(dev_id2))\n",
    "    dev_trip2 = create_trip(dev_data2, dev_id2)\n",
    "    dev_df2 = pd.DataFrame(dev_trip2)\n",
    "    dev_ds2 = Dataset.from_pandas(dev_df2)\n",
    "    tri_tokenized_datasets_task = dev_ds2.map(tri_tokenize_function, batched=True)\n",
    "    tri_tokenized_datasets_task = tri_tokenized_datasets_task.remove_columns([\"anchor\", \"positive\", \"negative\"])\n",
    "    tri_tokenized_datasets_task.set_format(\"torch\")\n",
    "    return tri_tokenized_datasets_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 150/150 [00:00<00:00, 1938.35 examples/s]\n",
      "/tmp/24976.1.interactive/ipykernel_2381633/865358520.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  anchor_ids = [torch.tensor(x['anchor_input_ids']) for x in features]\n",
      "/tmp/24976.1.interactive/ipykernel_2381633/865358520.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  positive_ids = [torch.tensor(x['positive_input_ids']) for x in features]\n",
      "/tmp/24976.1.interactive/ipykernel_2381633/865358520.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negative_ids = [torch.tensor(x['negative_input_ids']) for x in features]\n",
      "/tmp/24976.1.interactive/ipykernel_2381633/865358520.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  anchor_mask = [torch.tensor(x['anchor_attention_mask']) for x in features]\n",
      "/tmp/24976.1.interactive/ipykernel_2381633/865358520.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  positive_mask = [torch.tensor(x['positive_attention_mask']) for x in features]\n",
      "/tmp/24976.1.interactive/ipykernel_2381633/865358520.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negative_mask = [torch.tensor(x['negative_attention_mask']) for x in features]\n",
      "/tmp/24976.1.interactive/ipykernel_2381633/865358520.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = [torch.tensor(x['labels']) for x in features]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.1681417226791382,\n",
       " 'eval_model_preparation_time': 0.0022,\n",
       " 'eval_accuracy': 0.69,\n",
       " 'eval_recall': 0.9466666666666667,\n",
       " 'eval_precision': 0.6255506607929515,\n",
       " 'eval_f1': 0.753315649867374,\n",
       " 'eval_runtime': 0.7384,\n",
       " 'eval_samples_per_second': 203.148,\n",
       " 'eval_steps_per_second': 51.464,\n",
       " 'epoch': 9.970212765957447}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_qa = create_dev_task(\"QA\")\n",
    "trainer.evaluate(eval_dataset=dev_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/291 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 291/291 [00:00<00:00, 1746.61 examples/s]\n",
      "/tmp/24976.1.interactive/ipykernel_2381633/865358520.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  anchor_ids = [torch.tensor(x['anchor_input_ids']) for x in features]\n",
      "/tmp/24976.1.interactive/ipykernel_2381633/865358520.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  positive_ids = [torch.tensor(x['positive_input_ids']) for x in features]\n",
      "/tmp/24976.1.interactive/ipykernel_2381633/865358520.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negative_ids = [torch.tensor(x['negative_input_ids']) for x in features]\n",
      "/tmp/24976.1.interactive/ipykernel_2381633/865358520.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  anchor_mask = [torch.tensor(x['anchor_attention_mask']) for x in features]\n",
      "/tmp/24976.1.interactive/ipykernel_2381633/865358520.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  positive_mask = [torch.tensor(x['positive_attention_mask']) for x in features]\n",
      "/tmp/24976.1.interactive/ipykernel_2381633/865358520.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negative_mask = [torch.tensor(x['negative_attention_mask']) for x in features]\n",
      "/tmp/24976.1.interactive/ipykernel_2381633/865358520.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = [torch.tensor(x['labels']) for x in features]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9186015725135803,\n",
       " 'eval_model_preparation_time': 0.0022,\n",
       " 'eval_accuracy': 0.7972508591065293,\n",
       " 'eval_recall': 0.9381443298969072,\n",
       " 'eval_precision': 0.7319034852546917,\n",
       " 'eval_f1': 0.822289156626506,\n",
       " 'eval_runtime': 1.412,\n",
       " 'eval_samples_per_second': 206.093,\n",
       " 'eval_steps_per_second': 51.7,\n",
       " 'epoch': 9.970212765957447}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_d2t = create_dev_task(\"Data2txt\")\n",
    "trainer.evaluate(eval_dataset=dev_d2t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 192/192 [00:00<00:00, 1731.77 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/24976.1.interactive/ipykernel_2381633/865358520.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  anchor_ids = [torch.tensor(x['anchor_input_ids']) for x in features]\n",
      "/tmp/24976.1.interactive/ipykernel_2381633/865358520.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  positive_ids = [torch.tensor(x['positive_input_ids']) for x in features]\n",
      "/tmp/24976.1.interactive/ipykernel_2381633/865358520.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negative_ids = [torch.tensor(x['negative_input_ids']) for x in features]\n",
      "/tmp/24976.1.interactive/ipykernel_2381633/865358520.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  anchor_mask = [torch.tensor(x['anchor_attention_mask']) for x in features]\n",
      "/tmp/24976.1.interactive/ipykernel_2381633/865358520.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  positive_mask = [torch.tensor(x['positive_attention_mask']) for x in features]\n",
      "/tmp/24976.1.interactive/ipykernel_2381633/865358520.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negative_mask = [torch.tensor(x['negative_attention_mask']) for x in features]\n",
      "/tmp/24976.1.interactive/ipykernel_2381633/865358520.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = [torch.tensor(x['labels']) for x in features]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.7985296249389648,\n",
       " 'eval_model_preparation_time': 0.0022,\n",
       " 'eval_accuracy': 0.5442708333333334,\n",
       " 'eval_recall': 0.9583333333333334,\n",
       " 'eval_precision': 0.5242165242165242,\n",
       " 'eval_f1': 0.6777163904235729,\n",
       " 'eval_runtime': 0.9306,\n",
       " 'eval_samples_per_second': 206.318,\n",
       " 'eval_steps_per_second': 51.58,\n",
       " 'epoch': 9.970212765957447}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_sum = create_dev_task(\"Summary\")\n",
    "trainer.evaluate(eval_dataset=dev_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"./trained/triplet_rob\"\n",
    "trainer.save_model(name)\n",
    "trainer.save_state()\n",
    "tri_model.save_pretrained(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
