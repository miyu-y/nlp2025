{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"rag_truth_train.json\", \"r\") as f:\n",
    "    train_data = json.load(f)\n",
    "with open(\"rag_truth_dev.json\", \"r\") as f:\n",
    "    dev_data = json.load(f)\n",
    "with open(\"rag_truth_test.json\", \"r\") as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prefix(data):\n",
    "    for d in data:\n",
    "        d[\"text\"] = \"Please judge the following statement as true or false based on the references above: \" + d[\"text\"]\n",
    "    return data\n",
    "\n",
    "train_data = add_prefix(train_data)\n",
    "dev_data = add_prefix(dev_data)\n",
    "test_data = add_prefix(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_type: QA, Data2txt, Summary\n",
    "task_name = \"Data2txt\"\n",
    "train_data = [d for d in train_data if d[\"task_type\"] == task_name]\n",
    "dev_data = [d for d in dev_data if d[\"task_type\"] == task_name]\n",
    "test_data = [d for d in test_data if d[\"task_type\"] == task_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def create_trip(data, id_list):\n",
    "    trip = []\n",
    "    for id in id_list:\n",
    "        num = 0\n",
    "        no_hal = []\n",
    "        has_hal = []\n",
    "        for d in data:\n",
    "            if num == 6:\n",
    "                num = 0\n",
    "                if no_hal == [] or has_hal == []:\n",
    "                    break\n",
    "                # shuffle\n",
    "                random.seed(id) # change seed\n",
    "                no_hal = random.sample(no_hal, len(no_hal))\n",
    "                has_hal = random.sample(has_hal, len(has_hal))\n",
    "                \n",
    "                if len(no_hal)==1 or len(no_hal)==5:\n",
    "                    trip.append({\"anchor\":ref,\"positive\": no_hal[0], \"negative\": has_hal[0], \"labels\":[0,1]})\n",
    "                elif len(no_hal)==2 or len(no_hal)==4:\n",
    "                    trip.append({\"anchor\":ref,\"positive\": no_hal[0], \"negative\": has_hal[0], \"labels\":[0,1]})\n",
    "                    trip.append({\"anchor\":ref,\"positive\": no_hal[1], \"negative\": has_hal[1], \"labels\":[0,1]})\n",
    "                elif len(no_hal)==3:\n",
    "                    trip.append({\"anchor\":ref,\"positive\": no_hal[0], \"negative\": has_hal[0], \"labels\":[0,1]})\n",
    "                    trip.append({\"anchor\":ref,\"positive\": no_hal[1], \"negative\": has_hal[1], \"labels\":[0,1]})\n",
    "                    trip.append({\"anchor\":ref,\"positive\": no_hal[2], \"negative\": has_hal[2], \"labels\":[0,1]})\n",
    "                no_hal = []\n",
    "                has_hal = []\n",
    "                break\n",
    "            elif d[\"source_id\"] == id:\n",
    "                num +=1\n",
    "                ref = d[\"ref\"]\n",
    "                if d[\"labels\"] == 0:\n",
    "                    no_hal.append(d[\"text\"])\n",
    "                else: #hallucination\n",
    "                    has_hal.append(d[\"text\"])\n",
    "        if num == 6:\n",
    "            if len(no_hal)==1 or len(no_hal)==5:\n",
    "                trip.append({\"anchor\":ref,\"positive\": no_hal[0], \"negative\": has_hal[0], \"labels\":[0,1]})\n",
    "            elif len(no_hal)==2 or len(no_hal)==4:\n",
    "                trip.append({\"anchor\":ref,\"positive\": no_hal[0], \"negative\": has_hal[0], \"labels\":[0,1]})\n",
    "                trip.append({\"anchor\":ref,\"positive\": no_hal[1], \"negative\": has_hal[1], \"labels\":[0,1]})\n",
    "            elif len(no_hal)==3:\n",
    "                trip.append({\"anchor\":ref,\"positive\": no_hal[0], \"negative\": has_hal[0], \"labels\":[0,1]})\n",
    "                trip.append({\"anchor\":ref,\"positive\": no_hal[1], \"negative\": has_hal[1], \"labels\":[0,1]})\n",
    "                trip.append({\"anchor\":ref,\"positive\": no_hal[2], \"negative\": has_hal[2], \"labels\":[0,1]})\n",
    "    return trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2305 210 450\n"
     ]
    }
   ],
   "source": [
    "train_id = [d[\"source_id\"] for d in train_data]\n",
    "train_id = list(set(train_id))\n",
    "dev_id = [d[\"source_id\"] for d in dev_data]\n",
    "dev_id = list(set(dev_id))\n",
    "test_id = [d[\"source_id\"] for d in test_data]\n",
    "test_id = list(set(test_id))\n",
    "print(len(train_id), len(dev_id), len(test_id))\n",
    "train_trip = create_trip(train_data, train_id)\n",
    "dev_trip = create_trip(dev_data, dev_id)\n",
    "test_trip = create_trip(test_data, test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3760, 337, 633)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_trip), len(dev_trip), len(test_trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['anchor', 'positive', 'negative', 'labels'],\n",
       "        num_rows: 3760\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['anchor', 'positive', 'negative', 'labels'],\n",
       "        num_rows: 337\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['anchor', 'positive', 'negative', 'labels'],\n",
       "        num_rows: 633\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.DataFrame(train_trip)\n",
    "dev_df = pd.DataFrame(dev_trip)\n",
    "test_df = pd.DataFrame(test_trip)\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "dev_ds = Dataset.from_pandas(dev_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "\n",
    "tri_raw_datasets = DatasetDict({\"train\": train_ds, \"dev\": dev_ds, \"test\": test_ds})\n",
    "tri_raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tri_tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/RoBERTa-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anchor': \"{'question': 'how do cold and warm fronts work'}\",\n",
       " 'positive': 'Please judge the following statement as true or false based on the references above: A cold front occurs when a cold air mass moves in and replaces a warmer air mass. It is a transition zone from warm air to cold air, moving from northwest to southeast. The air behind a cold front is colder and drier than the air ahead of it. The distinction between a cold front and a warm front is which one is moving and pushing the other one away. A warm front, on the other hand, occurs when a warm air mass moves in and replaces a colder air mass. When a warm or cold front stops moving, it becomes a stationary front. Once it resumes its forward motion, it becomes a warm front or a cold front again.',\n",
       " 'negative': 'Please judge the following statement as true or false based on the references above: Based on the given passages, a cold front is the transition zone where a cold air mass is replacing a warmer air mass. It moves from northwest to southeast and the air behind it is noticeably colder and drier than the air ahead of it. On the other hand, a warm front is the transition zone where a warm air mass is replacing a cooler air mass. It moves from southwest to northeast and the air ahead of it is warmer and moister than the air behind it. If a front stops moving, it becomes a stationary front.',\n",
       " 'labels': [0, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_raw_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "def tri_tokenize_function(examples):\n",
    "    anchor = tri_tokenizer(examples[\"anchor\"], truncation=True,max_length=512,padding=\"max_length\")\n",
    "    positive = tri_tokenizer(examples[\"positive\"], truncation=True,max_length=512,padding=\"max_length\")\n",
    "    negative = tri_tokenizer(examples[\"negative\"], truncation=True,max_length=512,padding=\"max_length\")\n",
    "\n",
    "    return {\n",
    "        \"anchor_input_ids\": anchor[\"input_ids\"],\n",
    "        \"anchor_attention_mask\": anchor[\"attention_mask\"],\n",
    "        \"positive_input_ids\": positive[\"input_ids\"],\n",
    "        \"positive_attention_mask\": positive[\"attention_mask\"],\n",
    "        \"negative_input_ids\": negative[\"input_ids\"],\n",
    "        \"negative_attention_mask\": negative[\"attention_mask\"],\n",
    "    }\n",
    "\n",
    "tri_tokenized_datasets = tri_raw_datasets.map(tri_tokenize_function, batched=True)\n",
    "tri_tokenized_datasets = tri_tokenized_datasets.remove_columns([\"anchor\", \"positive\", \"negative\"])\n",
    "tri_data_collator = DataCollatorWithPadding(tokenizer=tri_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "class CustomDataCollator(DataCollatorWithPadding):\n",
    "    def __call__(self, features):\n",
    "        anchor_ids = [torch.tensor(x['anchor_input_ids']) for x in features]\n",
    "        positive_ids = [torch.tensor(x['positive_input_ids']) for x in features]\n",
    "        negative_ids = [torch.tensor(x['negative_input_ids']) for x in features]\n",
    "        \n",
    "        anchor_mask = [torch.tensor(x['anchor_attention_mask']) for x in features]\n",
    "        positive_mask = [torch.tensor(x['positive_attention_mask']) for x in features]\n",
    "        negative_mask = [torch.tensor(x['negative_attention_mask']) for x in features]\n",
    "        \n",
    "        anchor_ids = pad_sequence(anchor_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
    "        positive_ids = pad_sequence(positive_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
    "        negative_ids = pad_sequence(negative_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
    "        \n",
    "        anchor_mask = pad_sequence(anchor_mask, batch_first=True, padding_value=0)\n",
    "        positive_mask = pad_sequence(positive_mask, batch_first=True, padding_value=0)\n",
    "        negative_mask = pad_sequence(negative_mask, batch_first=True, padding_value=0)\n",
    "        \n",
    "        labels = [torch.tensor(x['labels']) for x in features]\n",
    "        \n",
    "        batch = {\n",
    "            \"input_ids\": [anchor_ids, positive_ids, negative_ids],\n",
    "            \"attention_mask\": [anchor_mask, positive_mask, negative_mask],\n",
    "            \"labels\": labels\n",
    "        }\n",
    "        \n",
    "        return batch\n",
    "\n",
    "\n",
    "tri_data_collator = CustomDataCollator(tokenizer=tri_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "base_model = AutoModel.from_pretrained(\"FacebookAI/RoBERTa-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "base_model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "def triplet_loss(anchor_output, positive_output, negative_output, positive_logits, negative_logits):\n",
    "    positive_targets = torch.zeros(positive_output.size(0), dtype=torch.long).to(device)  # no hallucination = 0\n",
    "    negative_targets = torch.ones(negative_output.size(0), dtype=torch.long).to(device)\n",
    "    positive_loss = nn.CrossEntropyLoss()(positive_logits, positive_targets)\n",
    "    negative_loss = nn.CrossEntropyLoss()(negative_logits, negative_targets)\n",
    "\n",
    "    classification_loss = (positive_loss + negative_loss) / 2.0 # average\n",
    "\n",
    "    triplet_loss_fn = (nn.TripletMarginWithDistanceLoss(margin=1.0,distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y)))\n",
    "    triplet_loss = triplet_loss_fn(anchor_output, positive_output, negative_output)\n",
    "   \n",
    "    return classification_loss, triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def compute_tri_metrics(eval_pred):\n",
    "    logits,labels= eval_pred\n",
    "    \n",
    "    # ModelOutput(logits=[positive_logits, negative_logits]...)\n",
    "    positive_logits = torch.tensor(logits[0])\n",
    "    negative_logits = torch.tensor(logits[1])\n",
    "\n",
    "    positive_preds = torch.argmax(positive_logits, dim=1)\n",
    "    negative_preds = torch.argmax(negative_logits, dim=1)\n",
    "\n",
    "    # num of correct predictions\n",
    "    correct_positive = (positive_preds == 0).sum().item()\n",
    "    correct_negative = (negative_preds == 1).sum().item()\n",
    "    \n",
    "    # total samples\n",
    "    total_samples = positive_preds.size(0) + negative_preds.size(0)\n",
    "    \n",
    "    positive_preds_num = (positive_preds == 1).sum().item() # predict non-hallucination samples (positive) as hallucination\n",
    "    negative_preds_num = (negative_preds == 1).sum().item() # predict hallucination samples (negative) as hallucination\n",
    "    negative_num = negative_preds.size(0) # num of hallucination samples\n",
    "\n",
    "    precision = negative_preds_num / (positive_preds_num + negative_preds_num) if (positive_preds_num + negative_preds_num) > 0 else 0\n",
    "    recall = negative_preds_num / negative_num if negative_num > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    accuracy = (correct_positive + correct_negative) / total_samples\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"recall\": recall,\n",
    "        \"precision\": precision,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "import torch\n",
    "from models_rob import TripletModel\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"steps\",  \n",
    "    save_steps=10000,\n",
    "    learning_rate=5e-6,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    fp16 = True,\n",
    "    gradient_accumulation_steps=3,\n",
    "    logging_dir=\"./logs\",\n",
    "    remove_unused_columns=False,\n",
    "    report_to=\"tensorboard\",\n",
    ")\n",
    "\n",
    "tri_model = TripletModel(base_model, triplet_loss)\n",
    "trainer = Trainer(\n",
    "    model=tri_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tri_tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tri_tokenized_datasets[\"dev\"],\n",
    "    data_collator=tri_data_collator,\n",
    "    tokenizer=tri_tokenizer,\n",
    "    compute_metrics=compute_tri_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='170' max='85' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [85/85 01:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.6933441162109375,\n",
       " 'eval_model_preparation_time': 0.0024,\n",
       " 'eval_accuracy': 0.49851632047477745,\n",
       " 'eval_recall': 0.005934718100890208,\n",
       " 'eval_precision': 0.4,\n",
       " 'eval_f1': 0.011695906432748539,\n",
       " 'eval_runtime': 4.8403,\n",
       " 'eval_samples_per_second': 69.624,\n",
       " 'eval_steps_per_second': 17.561}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3130' max='3130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3130/3130 15:35, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.497100</td>\n",
       "      <td>1.207629</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.695846</td>\n",
       "      <td>0.724036</td>\n",
       "      <td>0.685393</td>\n",
       "      <td>0.704185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.152500</td>\n",
       "      <td>1.117136</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.727003</td>\n",
       "      <td>0.813056</td>\n",
       "      <td>0.693671</td>\n",
       "      <td>0.748634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.004000</td>\n",
       "      <td>1.043206</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.732938</td>\n",
       "      <td>0.845697</td>\n",
       "      <td>0.690073</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.949000</td>\n",
       "      <td>1.178038</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.700297</td>\n",
       "      <td>0.928783</td>\n",
       "      <td>0.637475</td>\n",
       "      <td>0.756039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.872800</td>\n",
       "      <td>1.100712</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.725519</td>\n",
       "      <td>0.896142</td>\n",
       "      <td>0.668142</td>\n",
       "      <td>0.765526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.843500</td>\n",
       "      <td>1.070615</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.743323</td>\n",
       "      <td>0.884273</td>\n",
       "      <td>0.689815</td>\n",
       "      <td>0.775033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.792100</td>\n",
       "      <td>1.118366</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.732938</td>\n",
       "      <td>0.910979</td>\n",
       "      <td>0.671772</td>\n",
       "      <td>0.773300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3130, training_loss=0.9897091557804388, metrics={'train_runtime': 936.4163, 'train_samples_per_second': 40.153, 'train_steps_per_second': 3.343, 'total_flos': 0.0, 'train_loss': 0.9897091557804388, 'epoch': 9.98936170212766})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='159' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [159/159 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.1910415887832642,\n",
       " 'eval_model_preparation_time': 0.0024,\n",
       " 'eval_accuracy': 0.7116903633491312,\n",
       " 'eval_recall': 0.9146919431279621,\n",
       " 'eval_precision': 0.650561797752809,\n",
       " 'eval_f1': 0.7603414313854235,\n",
       " 'eval_runtime': 5.2242,\n",
       " 'eval_samples_per_second': 121.166,\n",
       " 'eval_steps_per_second': 30.435,\n",
       " 'epoch': 9.98936170212766}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=tri_tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dev_task(name):\n",
    "    dev_data2 = [d for d in test_data if d[\"task_type\"] == name]\n",
    "    dev_id2 = [d[\"source_id\"] for d in dev_data2]\n",
    "    dev_id2 = list(set(dev_id2))\n",
    "    dev_trip2 = create_trip(dev_data2, dev_id2)\n",
    "    dev_df2 = pd.DataFrame(dev_trip2)\n",
    "    dev_ds2 = Dataset.from_pandas(dev_df2)\n",
    "    tri_tokenized_datasets_task = dev_ds2.map(tri_tokenize_function, batched=True)\n",
    "    tri_tokenized_datasets_task = tri_tokenized_datasets_task.remove_columns([\"anchor\", \"positive\", \"negative\"])\n",
    "    tri_tokenized_datasets_task.set_format(\"torch\")\n",
    "    return tri_tokenized_datasets_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5683b9a9e894a3cbb45f4fb8f7906ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/24138.1.interactive/ipykernel_2222067/200384749.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  anchor_ids = [torch.tensor(x['anchor_input_ids']) for x in features]\n",
      "/tmp/24138.1.interactive/ipykernel_2222067/200384749.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  positive_ids = [torch.tensor(x['positive_input_ids']) for x in features]\n",
      "/tmp/24138.1.interactive/ipykernel_2222067/200384749.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negative_ids = [torch.tensor(x['negative_input_ids']) for x in features]\n",
      "/tmp/24138.1.interactive/ipykernel_2222067/200384749.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  anchor_mask = [torch.tensor(x['anchor_attention_mask']) for x in features]\n",
      "/tmp/24138.1.interactive/ipykernel_2222067/200384749.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  positive_mask = [torch.tensor(x['positive_attention_mask']) for x in features]\n",
      "/tmp/24138.1.interactive/ipykernel_2222067/200384749.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negative_mask = [torch.tensor(x['negative_attention_mask']) for x in features]\n",
      "/tmp/24138.1.interactive/ipykernel_2222067/200384749.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = [torch.tensor(x['labels']) for x in features]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0711263418197632,\n",
       " 'eval_model_preparation_time': 0.0024,\n",
       " 'eval_accuracy': 0.7266666666666667,\n",
       " 'eval_recall': 0.8866666666666667,\n",
       " 'eval_precision': 0.6717171717171717,\n",
       " 'eval_f1': 0.7643678160919541,\n",
       " 'eval_runtime': 1.1535,\n",
       " 'eval_samples_per_second': 130.034,\n",
       " 'eval_steps_per_second': 32.942,\n",
       " 'epoch': 9.98936170212766}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_qa = create_dev_task(\"QA\")\n",
    "trainer.evaluate(eval_dataset=dev_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91bfc76e4c5b41359e7b9b5c2921219c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/291 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/24138.1.interactive/ipykernel_2222067/200384749.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  anchor_ids = [torch.tensor(x['anchor_input_ids']) for x in features]\n",
      "/tmp/24138.1.interactive/ipykernel_2222067/200384749.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  positive_ids = [torch.tensor(x['positive_input_ids']) for x in features]\n",
      "/tmp/24138.1.interactive/ipykernel_2222067/200384749.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negative_ids = [torch.tensor(x['negative_input_ids']) for x in features]\n",
      "/tmp/24138.1.interactive/ipykernel_2222067/200384749.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  anchor_mask = [torch.tensor(x['anchor_attention_mask']) for x in features]\n",
      "/tmp/24138.1.interactive/ipykernel_2222067/200384749.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  positive_mask = [torch.tensor(x['positive_attention_mask']) for x in features]\n",
      "/tmp/24138.1.interactive/ipykernel_2222067/200384749.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negative_mask = [torch.tensor(x['negative_attention_mask']) for x in features]\n",
      "/tmp/24138.1.interactive/ipykernel_2222067/200384749.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = [torch.tensor(x['labels']) for x in features]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.8725352883338928,\n",
       " 'eval_model_preparation_time': 0.0024,\n",
       " 'eval_accuracy': 0.802405498281787,\n",
       " 'eval_recall': 0.9243986254295533,\n",
       " 'eval_precision': 0.7430939226519337,\n",
       " 'eval_f1': 0.8238897396630935,\n",
       " 'eval_runtime': 2.2254,\n",
       " 'eval_samples_per_second': 130.766,\n",
       " 'eval_steps_per_second': 32.804,\n",
       " 'epoch': 9.98936170212766}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_d2t = create_dev_task(\"Data2txt\")\n",
    "trainer.evaluate(eval_dataset=dev_d2t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adcd8b345e83451fae7de8a24e5cd91d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/192 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/24138.1.interactive/ipykernel_2222067/200384749.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  anchor_ids = [torch.tensor(x['anchor_input_ids']) for x in features]\n",
      "/tmp/24138.1.interactive/ipykernel_2222067/200384749.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  positive_ids = [torch.tensor(x['positive_input_ids']) for x in features]\n",
      "/tmp/24138.1.interactive/ipykernel_2222067/200384749.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negative_ids = [torch.tensor(x['negative_input_ids']) for x in features]\n",
      "/tmp/24138.1.interactive/ipykernel_2222067/200384749.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  anchor_mask = [torch.tensor(x['anchor_attention_mask']) for x in features]\n",
      "/tmp/24138.1.interactive/ipykernel_2222067/200384749.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  positive_mask = [torch.tensor(x['positive_attention_mask']) for x in features]\n",
      "/tmp/24138.1.interactive/ipykernel_2222067/200384749.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  negative_mask = [torch.tensor(x['negative_attention_mask']) for x in features]\n",
      "/tmp/24138.1.interactive/ipykernel_2222067/200384749.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = [torch.tensor(x['labels']) for x in features]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.7708507776260376,\n",
       " 'eval_model_preparation_time': 0.0024,\n",
       " 'eval_accuracy': 0.5625,\n",
       " 'eval_recall': 0.921875,\n",
       " 'eval_precision': 0.5363636363636364,\n",
       " 'eval_f1': 0.6781609195402298,\n",
       " 'eval_runtime': 1.4686,\n",
       " 'eval_samples_per_second': 130.739,\n",
       " 'eval_steps_per_second': 32.685,\n",
       " 'epoch': 9.98936170212766}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_sum = create_dev_task(\"Summary\")\n",
    "trainer.evaluate(eval_dataset=dev_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"./0102_triplet_rob\"\n",
    "trainer.save_model(name)\n",
    "trainer.save_state()\n",
    "tri_model.save_pretrained(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
