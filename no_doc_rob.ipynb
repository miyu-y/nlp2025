{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## no_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"dataset/rag_truth_train.json\", \"r\") as f:\n",
    "    train_data = json.load(f)\n",
    "with open(\"dataset/rag_truth_dev.json\", \"r\") as f:\n",
    "    dev_data = json.load(f)\n",
    "with open(\"dataset/rag_truth_test.json\", \"r\") as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prefix(data):\n",
    "    for d in data:\n",
    "        d[\"text\"] = \"Please judge the following statement whether it includes hallucination or not: \" + d[\"text\"]\n",
    "    return data\n",
    "\n",
    "\n",
    "train_data = add_prefix(train_data)\n",
    "dev_data = add_prefix(dev_data)\n",
    "test_data = add_prefix(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_type: QA, Data2txt, Summary\n",
    "# Run when you want to train only on specific tasks\n",
    "task_name = \"Summary\"\n",
    "train_data = [d for d in train_data if d[\"task_type\"] == task_name]\n",
    "dev_data = [d for d in dev_data if d[\"task_type\"] == task_name]\n",
    "test_data = [d for d in test_data if d[\"task_type\"] == task_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ref', 'text', 'labels', 'source', 'model', 'task_type', 'source_id'],\n",
       "        num_rows: 13830\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['ref', 'text', 'labels', 'source', 'model', 'task_type', 'source_id'],\n",
       "        num_rows: 1260\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ref', 'text', 'labels', 'source', 'model', 'task_type', 'source_id'],\n",
       "        num_rows: 2700\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.DataFrame(train_data)\n",
    "dev_df = pd.DataFrame(dev_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "dev_ds = Dataset.from_pandas(dev_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "\n",
    "raw_datasets = DatasetDict({\"train\": train_ds, \"dev\":dev_ds, \"test\": test_ds})\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 13830/13830 [00:01<00:00, 11554.91 examples/s]\n",
      "Map: 100%|██████████| 1260/1260 [00:00<00:00, 11916.25 examples/s]\n",
      "Map: 100%|██████████| 2700/2700 [00:00<00:00, 12444.99 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=512)\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "base_model = AutoModel.from_pretrained(\"FacebookAI/RoBERTa-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "base_model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    logits = logits[0]\n",
    "    predictions = np.argmax(logits, axis=-1).tolist()  \n",
    "    labels = labels.tolist()  \n",
    "\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    recall = recall_score(labels, predictions)\n",
    "    precision = precision_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions)\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"recall\": recall, \"precision\": precision, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import torch\n",
    "from models_rob import NoDocModel\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=10000,\n",
    "    learning_rate=5e-6,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    gradient_accumulation_steps=12,\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"tensorboard\",\n",
    ")\n",
    "\n",
    "model = NoDocModel(base_model)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"dev\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/315 00:00 < 00:02, 109.52 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6966366767883301,\n",
       " 'eval_model_preparation_time': 0.0024,\n",
       " 'eval_accuracy': 0.4238095238095238,\n",
       " 'eval_recall': 0.9981308411214953,\n",
       " 'eval_precision': 0.42414614773629866,\n",
       " 'eval_f1': 0.5953177257525084,\n",
       " 'eval_runtime': 2.4374,\n",
       " 'eval_samples_per_second': 516.951,\n",
       " 'eval_steps_per_second': 129.238}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2880' max='2880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2880/2880 12:47, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.583900</td>\n",
       "      <td>0.556482</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.707937</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.638474</td>\n",
       "      <td>0.676626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.521700</td>\n",
       "      <td>0.502189</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.637383</td>\n",
       "      <td>0.773243</td>\n",
       "      <td>0.698770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.502900</td>\n",
       "      <td>0.526865</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.745238</td>\n",
       "      <td>0.725234</td>\n",
       "      <td>0.690391</td>\n",
       "      <td>0.707384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.481400</td>\n",
       "      <td>0.590561</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.668254</td>\n",
       "      <td>0.831776</td>\n",
       "      <td>0.575679</td>\n",
       "      <td>0.680428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.462600</td>\n",
       "      <td>0.541642</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.717460</td>\n",
       "      <td>0.770093</td>\n",
       "      <td>0.638760</td>\n",
       "      <td>0.698305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.446500</td>\n",
       "      <td>0.598241</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.831776</td>\n",
       "      <td>0.595716</td>\n",
       "      <td>0.694228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.427300</td>\n",
       "      <td>0.646027</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.663492</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.568603</td>\n",
       "      <td>0.684524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.410500</td>\n",
       "      <td>0.594088</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.703968</td>\n",
       "      <td>0.801869</td>\n",
       "      <td>0.616379</td>\n",
       "      <td>0.696994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.391500</td>\n",
       "      <td>0.679329</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.664286</td>\n",
       "      <td>0.857944</td>\n",
       "      <td>0.569479</td>\n",
       "      <td>0.684564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2880, training_loss=0.46301840941111244, metrics={'train_runtime': 768.2196, 'train_samples_per_second': 180.027, 'train_steps_per_second': 3.749, 'total_flos': 0.0, 'train_loss': 0.46301840941111244, 'epoch': 9.96818970503181})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 17/675 00:00 < 00:07, 88.67 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7494223713874817,\n",
       " 'eval_model_preparation_time': 0.0024,\n",
       " 'eval_accuracy': 0.6511111111111111,\n",
       " 'eval_recall': 0.8568398727465536,\n",
       " 'eval_precision': 0.5003095975232198,\n",
       " 'eval_f1': 0.6317435496481626,\n",
       " 'eval_runtime': 5.2273,\n",
       " 'eval_samples_per_second': 516.515,\n",
       " 'eval_steps_per_second': 129.129,\n",
       " 'epoch': 9.96818970503181}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on each task\n",
    "def create_dev_task(name):\n",
    "    dev_data2 = [d for d in test_data if d[\"task_type\"] == name]\n",
    "    dev_df2 = pd.DataFrame(dev_data2)\n",
    "    dev_ds2 = Dataset.from_pandas(dev_df2)\n",
    "    tokenized_datasets_task = dev_ds2.map(tokenize_function, batched=True)\n",
    "    tokenized_datasets_task = tokenized_datasets_task.remove_columns([\"text\"])\n",
    "    return tokenized_datasets_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/900 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 900/900 [00:00<00:00, 8884.67 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.8223901391029358,\n",
       " 'eval_model_preparation_time': 0.0024,\n",
       " 'eval_accuracy': 0.6244444444444445,\n",
       " 'eval_recall': 0.8125,\n",
       " 'eval_precision': 0.2968036529680365,\n",
       " 'eval_f1': 0.43478260869565216,\n",
       " 'eval_runtime': 2.2346,\n",
       " 'eval_samples_per_second': 402.762,\n",
       " 'eval_steps_per_second': 100.691,\n",
       " 'epoch': 9.96818970503181}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_qa = create_dev_task(\"QA\")\n",
    "trainer.evaluate(eval_dataset=dev_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 900/900 [00:00<00:00, 10057.10 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6488045454025269,\n",
       " 'eval_model_preparation_time': 0.0024,\n",
       " 'eval_accuracy': 0.7544444444444445,\n",
       " 'eval_recall': 0.9499136442141624,\n",
       " 'eval_precision': 0.7412398921832885,\n",
       " 'eval_f1': 0.8327024981074943,\n",
       " 'eval_runtime': 2.1812,\n",
       " 'eval_samples_per_second': 412.626,\n",
       " 'eval_steps_per_second': 103.157,\n",
       " 'epoch': 9.96818970503181}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_d2t = create_dev_task(\"Data2txt\")\n",
    "trainer.evaluate(eval_dataset=dev_d2t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 900/900 [00:00<00:00, 13057.60 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7770723700523376,\n",
       " 'eval_model_preparation_time': 0.0024,\n",
       " 'eval_accuracy': 0.5744444444444444,\n",
       " 'eval_recall': 0.6274509803921569,\n",
       " 'eval_precision': 0.2942528735632184,\n",
       " 'eval_f1': 0.40062597809076683,\n",
       " 'eval_runtime': 2.2557,\n",
       " 'eval_samples_per_second': 398.995,\n",
       " 'eval_steps_per_second': 99.749,\n",
       " 'epoch': 9.96818970503181}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_sum = create_dev_task(\"Summary\")\n",
    "trainer.evaluate(eval_dataset=dev_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model\n",
    "name = \"./trained/no_doc_rob\"\n",
    "trainer.save_model(name)\n",
    "trainer.save_state()\n",
    "model.save_pretrained(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
